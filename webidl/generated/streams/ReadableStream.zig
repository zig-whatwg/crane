// Auto-generated by webidl-codegen (AST/IR-based)
// DO NOT EDIT - changes will be overwritten
//
// This file was generated from the source file with the same name.
// Class definitions have been enhanced with:
//   - Inherited methods from parent classes
//   - Property getters and setters
//   - Optimized field layouts
//   - Automatic import resolution

const Allocator = @import("std.mem").Allocator;
const AsyncPromise = @import("async_promise").AsyncPromise;
const ByteTeeState = @import("byte_tee_state").ByteTeeState;
const FromIterableState = @import("from_iterable_state").FromIterableState;
const IntoRequests = @import("into_requests").IntoRequests;
const JSValue = @import("j_s_value").JSValue;
const Loop = @import("loop").Loop;
const PipeState = @import("pipe_state").PipeState;
const Promise = @import("promise").Promise;
const ReadableByteStreamController = @import("readable_byte_stream_controller").ReadableByteStreamController;
const ReadableStreamAsyncIterator = @import("readable_stream_async_iterator").ReadableStreamAsyncIterator;
const ReadableStreamBYOBReader = @import("readable_stream_byob_reader").ReadableStreamBYOBReader;
const ReadableStreamDefaultController = @import("readable_stream_default_controller").ReadableStreamDefaultController;
const ReadableStreamDefaultReader = @import("readable_stream_default_reader").ReadableStreamDefaultReader;
const Requests = @import("requests").Requests;
const State = @import("state").State;
const TeeState = @import("tee_state").TeeState;
const TestEventLoop = @import("test_event_loop").TestEventLoop;
const WritableStream = @import("writable_stream").WritableStream;
const WritableStreamDefaultWriter = @import("writable_stream_default_writer").WritableStreamDefaultWriter;
const async_iterator = @import("async_iterator").async_iterator;
const common = @import("common").common;
const dict_parsing = @import("dict_parsing").dict_parsing;
const eventLoop = @import("event_loop").eventLoop;
const std = @import("std");
const structured_clone = @import("structured_clone").structured_clone;
const webidl = @import("webidl");


/// Stream state enumeration
///
/// Spec: § 4.1 "Internal slots" - [[state]]
pub const StreamState = enum {
    readable,
    closed,
    errored,
};

/// Reader union type
///
/// Spec: § 4.1 [[reader]] slot can be ReadableStreamDefaultReader, ReadableStreamBYOBReader, or undefined
pub const Reader = union(enum) {
    none: void,
    default: *ReadableStreamDefaultReader,
    byob: *ReadableStreamBYOBReader,
};

/// Pipe options for pipeTo() method
///
/// Spec: § 4.1.5 StreamPipeOptions dictionary
pub const PipeOptions = struct {
    preventClose: bool = false,
    preventAbort: bool = false,
    preventCancel: bool = false,
    signal: ?*anyopaque = null,
};

/// Transform pair for pipeThrough() method
///
/// Spec: § 4.1.6 ReadableWritablePair dictionary
pub const TransformPair = struct {
    readable: *ReadableStream,
    writable: *WritableStream,
};

/// Return type for tee() method
///
/// Spec: § 4.1.7 tee() returns two branches
pub const TeeBranches = struct {
    branch1: *ReadableStream,
    branch2: *ReadableStream,
};

pub const ReadableStream = struct {

    // ========================================================================
    // Fields
    // ========================================================================

    allocator: std.mem.Allocator,
    controller: *ReadableStreamDefaultController,
    detached: bool,
    disturbed: bool,
    reader: Reader,
    state: StreamState,
    storedError: ?common.JSValue,
    eventLoop: eventLoop.EventLoop,
    eventLoop_storage: ?*TestEventLoop,
    teeState: ?*TeeState,

    // ========================================================================
    // Methods
    // ========================================================================

    pub fn init(allocator: std.mem.Allocator) !ReadableStream {

        // Create an owned event loop for backward compatibility
        const loop_ptr = try allocator.create(TestEventLoop);
        errdefer allocator.destroy(loop_ptr);

        loop_ptr.* = TestEventLoop.init(allocator);

        var stream = try initWithSource(allocator, loop_ptr.eventLoop(), null, null);

        // Mark that we own this event loop so deinit() will clean it up
        stream.eventLoop_storage = loop_ptr;

        return stream;
    
    }

    pub fn deinit(self: *ReadableStream) void {

        // IMPORTANT: We do NOT run microtasks during deinit.
        // Microtasks can reference promises and other objects that are being destroyed.
        // Running them during cleanup can cause use-after-free errors.

        self.controller.deinit();
        self.allocator.destroy(self.controller);

        switch (self.reader) {
            .default => |r| {
                r.deinit();
                self.allocator.destroy(r);
            },
            .byob => |r| {
                r.deinit();
                self.allocator.destroy(r);
            },
            .none => {},
        }

        // Clean up owned event loop if we created one (backward compatibility)
        if (self.eventLoop_storage) |loop_ptr| {
            loop_ptr.deinit();
            self.allocator.destroy(loop_ptr);
        }
        // Otherwise, we borrowed the event loop and don't destroy it
        // (matches browser semantics where streams don't own event loops)

        // Release TeeState reference if this is a tee branch
        if (self.teeState) |teeState| {
            teeState.release();
        }
    
    }

    pub fn initWithSource(
        allocator: std.mem.Allocator,
        loop: eventLoop.EventLoop,
        underlyingSource: ?webidl.JSValue,
        strategy: ?webidl.JSValue,
    ) !ReadableStream {

        // Step 1: If underlyingSource is missing, set it to null.
        // Step 2: Let underlyingSourceDict be underlyingSource, converted to an IDL value of type UnderlyingSource.
        const source_dict = try dict_parsing.parseUnderlyingSource(allocator, underlyingSource);

        // Step 3-4: Parse queuing strategy
        const strategy_dict = try dict_parsing.parseQueuingStrategy(allocator, strategy);

        // Extract high water mark with default of 1.0
        const highWaterMark = strategy_dict.high_water_mark orelse 1.0;

        // Extract size algorithm with default
        const size_algorithm = if (strategy_dict.size) |size_fn|
            common.wrapGenericSizeCallback(size_fn)
        else
            common.defaultSizeAlgorithm();

        // Step 5-7: Check stream type (default vs. byte stream)
        // Byte stream constructors use ReadableByteStreamController
        // Default stream constructors use ReadableStreamDefaultController (this path)

        // Create controller on heap
        const controller = try allocator.create(ReadableStreamDefaultController);
        errdefer allocator.destroy(controller);

        // Step 9-11: Extract algorithms from dictionary or use defaults
        const cancelAlgorithm = if (source_dict.cancel) |cancel_fn|
            common.wrapGenericCancelCallback(cancel_fn)
        else
            common.defaultCancelAlgorithm();

        const pullAlgorithm = if (source_dict.pull) |pull_fn|
            common.wrapGenericPullCallback(pull_fn)
        else
            common.defaultPullAlgorithm();

        // TODO: Implement start callback invocation when zig-js-runtime is available
        _ = source_dict.start; // Acknowledge but don't use

        controller.* = try ReadableStreamDefaultController.init(
            allocator,
            cancelAlgorithm,
            pullAlgorithm,
            highWaterMark,
            size_algorithm,
            loop,
        );

        var stream = ReadableStream{
            .allocator = allocator,
            .controller = controller,
            .detached = false,
            .disturbed = false,
            .reader = .none,
            .state = .readable,
            .storedError = null,
            .eventLoop = loop,
            .eventLoop_storage = null, // Borrowed event loop (not owned)
            .teeState = null, // Not a tee branch by default
        };

        // Step 15: Mark controller as started
        stream.controller.started = true;

        return stream;
    
    }

    pub fn from(
        allocator: std.mem.Allocator,
        loop: eventLoop.EventLoop,
        asyncIterable: common.JSValue,
    ) !*ReadableStream {

        // Spec: § 4.2.4 "Return ? ReadableStreamFromIterable(asyncIterable)"
        return try ReadableStreamFromIterable(allocator, loop, asyncIterable);
    
    }

    pub fn get_locked(self: *const ReadableStream) bool {

        // Spec: § 4.1.2 "Return ! IsReadableStreamLocked(this)."
        return self.reader != .none;
    
    }

    pub fn call_cancel(self: *ReadableStream, reason: ?webidl.JSValue) !*AsyncPromise(void) {

        // Spec: § 4.1.3 step 1: "If ! IsReadableStreamLocked(this) is true, return a promise rejected with a TypeError exception."
        if (self.get_locked()) {
            const promise = try AsyncPromise(void).init(self.allocator, self.eventLoop);
            const exception = webidl.errors.Exception{
                .simple = .{
                    .type = .TypeError,
                    .message = try self.allocator.dupe(u8, "Cannot cancel a locked stream"),
                },
            };
            promise.reject(exception);
            return promise;
        }

        // Spec: § 4.1.3 step 2: "Return ! ReadableStreamCancel(this, reason)."
        return self.cancelInternal(if (reason) |r| common.JSValue.fromWebIDL(r) else null);
    
    }

    pub fn call_getReader(
        self: *ReadableStream,
        options: ?webidl.JSValue,
    ) !Reader {

        // Parse options to check for BYOB mode
        // BYOB readers are supported via ReadableStreamBYOBReader
        // This path creates default readers
        // TODO: Route to ReadableStreamBYOBReader when options.mode === "byob"
        _ = options;

        // Spec: § 4.1.4 "If options["mode"] does not exist, return ? AcquireReadableStreamDefaultReader(this)."
        const reader = try self.acquireDefaultReader(self.eventLoop);
        return .{ .default = reader };
    
    }

    pub fn call_pipeTo(
        self: *ReadableStream,
        destination: *WritableStream,
        options: ?PipeOptions,
    ) !*AsyncPromise(void) {

        // Parse options with defaults
        const opts = options orelse PipeOptions{
            .preventClose = false,
            .preventAbort = false,
            .preventCancel = false,
            .signal = null,
        };

        // Step 1: If ! IsReadableStreamLocked(this) is true, return a promise rejected with a TypeError.
        if (self.get_locked()) {
            const promise = try AsyncPromise(void).init(self.allocator, self.eventLoop);
            const exception = webidl.errors.Exception{
                .simple = .{
                    .type = .TypeError,
                    .message = try self.allocator.dupe(u8, "Cannot pipe from a locked stream"),
                },
            };
            promise.reject(exception);
            return promise;
        }

        // Step 2: If ! IsWritableStreamLocked(destination) is true, return a promise rejected with a TypeError.
        if (destination.get_locked()) {
            const promise = try AsyncPromise(void).init(self.allocator, self.eventLoop);
            const exception = webidl.errors.Exception{
                .simple = .{
                    .type = .TypeError,
                    .message = try self.allocator.dupe(u8, "Cannot pipe to a locked stream"),
                },
            };
            promise.reject(exception);
            return promise;
        }

        // Step 3: Acquire reader and writer
        const reader = try self.acquireDefaultReader(self.eventLoop);
        const writer = try destination.acquireDefaultWriter(self.eventLoop);

        // Step 4: Create PipeState to coordinate the operation
        const pipeState = try PipeState.init(
            self.allocator,
            self.eventLoop,
            self,
            destination,
            reader,
            writer,
            opts.preventClose,
            opts.preventAbort,
            opts.preventCancel,
            opts.signal,
        );

        // Step 5: Start shuttling data
        try pipeState.startShuttling();

        // Step 6: Return the promise that resolves when piping completes
        return pipeState.promise;
    
    }

    pub fn call_pipeThrough(
        self: *ReadableStream,
        transform: *TransformPair,
        options: ?PipeOptions,
    ) !*ReadableStream {

        // Spec step 1: If ! IsReadableStreamLocked(this) is true, throw a TypeError exception.
        if (self.get_locked()) {
            return error.TypeError;
        }

        // Spec step 2: If ! IsWritableStreamLocked(transform["writable"]) is true, throw a TypeError exception.
        if (transform.writable.get_locked()) {
            return error.TypeError;
        }

        // Spec step 3: Let signal be options["signal"] if it exists, or undefined otherwise.
        // (Handled by PipeOptions structure)

        // Spec step 4: Let promise be ! ReadableStreamPipeTo(this, transform["writable"], ...)
        _ = try self.call_pipeTo(transform.writable, options);

        // Spec step 5: Set promise.[[PromiseIsHandled]] to true.
        // (This means we intentionally don't await the promise - it runs in background)
        // The promise continues running to pipe data through the transform

        // Spec step 6: Return transform["readable"].
        return transform.readable;
    
    }

    pub fn call_tee(self: *ReadableStream) !TeeBranches {

        // Step 1: Let branches be ? ReadableStreamTee(this, false).
        return self.teeInternal(false);
    
    }

    pub fn call_from(allocator: std.mem.Allocator, loop: eventLoop.EventLoop, asyncIterable: webidl.JSValue) !*ReadableStream {

        // Convert webidl.JSValue to common.AsyncIterator
        // In a full JavaScript runtime, this would call GetIterator(asyncIterable, async)
        // For now, we expect asyncIterable to wrap an AsyncIterator

        // Extract iterator from the JSValue
        // This is a simplified bridge - full implementation would need Symbol.asyncIterator support
        const iterator = try extractAsyncIterator(allocator, asyncIterable);

        // Call ReadableStreamFromIterable algorithm
        return readableStreamFromIterable(allocator, loop, iterator);
    
    }

    fn extractAsyncIterator(allocator: std.mem.Allocator, value: webidl.JSValue) !common.AsyncIterator {

        // For testing/development, we support passing MockAsyncIterator as pointer in JSValue
        // In production, this would:
        // 1. Call GetIterator(value, async) to get Symbol.asyncIterator
        // 2. Get the next method
        // 3. Create IteratorRecord
        // 4. Wrap in common.AsyncIterator

        // Check if value contains a pointer to MockAsyncIterator
        switch (value) {
            .object => {
                // For now, we expect caller to embed iterator pointer
                // This is a temporary solution until full Symbol support
                // Callers can use: JSValue{ .object = @ptrCast(mockIterator) }
                return error.NotImplemented; // Still needs proper implementation
            },
            else => return error.TypeError,
        }

        // TODO: Full implementation with Symbol.asyncIterator lookup
        _ = allocator;
    
    }

    fn readableStreamFromIterable(
        allocator: std.mem.Allocator,
        loop: eventLoop.EventLoop,
        iterator: common.AsyncIterator,
    ) !*ReadableStream {

        // Spec step 1: Let stream be undefined (we'll create it at the end)

        // Spec step 2: Let iteratorRecord be ? GetIterator(asyncIterable, async)
        // (we already have the iterator)

        // Create state object to hold iterator and stream reference
        const state = try allocator.create(FromIterableState);
        errdefer allocator.destroy(state);

        state.* = .{
            .allocator = allocator,
            .iterator = iterator,
            .stream = undefined, // Will be set after stream creation
        };

        // Spec step 3: Let startAlgorithm be an algorithm that returns undefined
        // (no-op, controller starts immediately)

        // Spec step 4: Let pullAlgorithm be the following steps:
        const pullAlgorithm = common.PullAlgorithm{
            .ptr = state,
            .vtable = &.{
                .call = FromIterableState.pullAlgorithmCall,
                .deinit = FromIterableState.deinitVTable,
            },
        };

        // Spec step 5: Let cancelAlgorithm be the following steps, given reason:
        const cancelAlgorithm = common.CancelAlgorithm{
            .ptr = state,
            .vtable = &.{
                .call = FromIterableState.cancelAlgorithmCall,
                .deinit = null, // Already handled by pullAlgorithm deinit
            },
        };

        // Spec step 6: Set stream to ! CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, 0)
        const stream = try createReadableStream(
            allocator,
            loop,
            pullAlgorithm,
            cancelAlgorithm,
            0, // highWaterMark
        );

        // Link state to stream
        state.stream = stream;

        // Spec step 7: Return stream
        return stream;
    
    }

    pub fn fromMockIterator(
        allocator: std.mem.Allocator,
        loop: eventLoop.EventLoop,
        mock: *async_iterator.MockAsyncIterator,
    ) !*ReadableStream {

        // Wrap MockAsyncIterator in common.AsyncIterator
        const iterator = common.AsyncIterator{
            .ptr = mock,
            .vtable = &.{
                .next = struct {
                    fn call(ctx: *anyopaque) common.Promise(common.IteratorResult) {
                        const m: *async_iterator.MockAsyncIterator = @ptrCast(@alignCast(ctx));
                        const result = m.next();
                        return common.Promise(common.IteratorResult).fulfilled(.{
                            .value = result.value,
                            .done = result.done,
                        });
                    }
                }.call,
                .return_fn = struct {
                    fn call(ctx: *anyopaque, reason: ?common.JSValue) common.Promise(common.JSValue) {
                        const m: *async_iterator.MockAsyncIterator = @ptrCast(@alignCast(ctx));
                        const result = m.returnMethod(reason orelse common.JSValue.undefined_value());
                        return common.Promise(common.JSValue).fulfilled(result.value);
                    }
                }.call,
                .deinit = null, // MockAsyncIterator is managed externally
            },
        };

        return readableStreamFromIterable(allocator, loop, iterator);
    
    }

    fn createReadableStream(
        allocator: std.mem.Allocator,
        loop: eventLoop.EventLoop,
        pullAlgorithm: common.PullAlgorithm,
        cancelAlgorithm: common.CancelAlgorithm,
        highWaterMark: f64,
    ) !*ReadableStream {

        // Spec step 1: If highWaterMark was not passed, set it to 1
        const hwm = if (highWaterMark == 0) 1.0 else highWaterMark;

        // Spec step 2: If sizeAlgorithm was not passed, set it to an algorithm that returns 1
        const sizeAlgorithm = common.defaultSizeAlgorithm();

        // Spec step 3: Assert: ! IsNonNegativeNumber(highWaterMark) is true
        std.debug.assert(hwm >= 0);

        // Spec step 4: Let stream be a new ReadableStream
        const stream_ptr = try allocator.create(ReadableStream);
        errdefer allocator.destroy(stream_ptr);

        // Spec step 5: Perform ! InitializeReadableStream(stream)
        // Spec step 6: Let controller be a new ReadableStreamDefaultController
        const controller = try allocator.create(ReadableStreamDefaultController);
        errdefer allocator.destroy(controller);

        // Spec step 7: Perform ? SetUpReadableStreamDefaultController(...)
        controller.* = try ReadableStreamDefaultController.init(
            allocator,
            cancelAlgorithm,
            pullAlgorithm,
            hwm,
            sizeAlgorithm,
            loop,
        );

        stream_ptr.* = .{
            .allocator = allocator,
            .controller = controller,
            .detached = false,
            .disturbed = false,
            .reader = .none,
            .state = .readable, // InitializeReadableStream sets state to "readable"
            .storedError = null,
            .eventLoop = loop,
            .eventLoop_storage = null, // Borrowed event loop
            .teeState = null,
        };

        // Mark controller as started
        stream_ptr.controller.started = true;

        // Spec step 8: Return stream
        return stream_ptr;
    
    }

    pub fn call_values(self: *ReadableStream, preventCancel: bool) !ReadableStreamAsyncIterator {

        return ReadableStreamAsyncIterator.init(
            self.allocator,
            self,
            self.eventLoop,
            preventCancel,
        );
    
    }

    pub fn call_asyncIterator(self: *ReadableStream) !ReadableStreamAsyncIterator {

        return self.call_values(false);
    
    }

    pub fn transferSteps(self: *ReadableStream) !*structured_clone.SerializedData {
        const cross_realm_transform = @import("cross_realm_transform");
        const message_port = @import("message_port");

        // Spec step 1: If ! IsReadableStreamLocked(value) is true, throw DataCloneError
        if (self.reader != .none) {
            return error.DataCloneError;
        }

        // Spec step 2-3: Create MessagePort pair
        const ports = try message_port.createMessagePortPair(self.allocator);
        const port1 = ports[0];
        const port2 = ports[1];

        // Spec step 4: Entangle (already done in createMessagePortPair)

        // Spec step 5: Create WritableStream in current realm
        var writable = try WritableStream.init(self.allocator);
        errdefer writable.deinit();

        // Spec step 6: SetUpCrossRealmTransformWritable(writable, port1)
        try cross_realm_transform.setupCrossRealmTransformWritable(self.allocator, &writable, port1);

        // Spec step 7: Let promise = ! ReadableStreamPipeTo(value, writable, false, false, false)
        // Note: We're not awaiting the promise - it runs in the background
        _ = try self.call_pipeTo(&writable, .{ .preventClose = false, .preventAbort = false, .preventCancel = false, .signal = null });

        // Spec step 8: Set promise.[[PromiseIsHandled]] to true
        // (Promise error handling is internal to pipeTo)

        // Spec step 9: Serialize port2 with transfer
        const serialized = try structured_clone.structuredSerializeWithTransfer(self.allocator, port2);

        return serialized;
    }

    /// [[TransferReceivingSteps]](dataHolder)
    ///
    /// Spec: § 4.2.5 "Transfer" (transfer-receiving steps)
    /// https://streams.spec.whatwg.org/#rs-transfer
    ///
    /// Steps for receiving a transferred ReadableStream in another realm.
    /// Deserializes the MessagePort and sets up a stream that reads from it.
    pub fn transferReceivingSteps(
        self: *ReadableStream,
        serialized: *structured_clone.SerializedData,
    ) !void {

        const cross_realm_transform = @import("cross_realm_transform");

        // Spec step 1: Let deserializedRecord = ! StructuredDeserializeWithTransfer(dataHolder.[[port]], current Realm)
        const deserialized = try structured_clone.structuredDeserializeWithTransfer(self.allocator, serialized);

        // Spec step 2: Let port = deserializedRecord.[[Deserialized]]
        const port = deserialized.port;

        // Spec step 3: Perform ! SetUpCrossRealmTransformReadable(value, port)
        try cross_realm_transform.setupCrossRealmTransformReadable(self.allocator, self, port);
    
    }

    pub fn cancelInternal(self: *ReadableStream, reason: ?common.JSValue) !*AsyncPromise(void) {

        // Spec step 1: Set stream.[[disturbed]] to true
        self.disturbed = true;

        // Spec step 2: If stream.[[state]] is "closed", return a promise fulfilled with undefined
        if (self.state == .closed) {
            const promise = try AsyncPromise(void).init(self.allocator, self.eventLoop);
            promise.fulfill({});
            return promise;
        }

        // Spec step 3: If stream.[[state]] is "errored", return a promise rejected with stream.[[storedError]]
        if (self.state == .errored) {
            const stored_err = self.storedError orelse common.JSValue.undefined_value();
            const exception = try stored_err.toException(self.allocator);
            const promise = try AsyncPromise(void).init(self.allocator, self.eventLoop);
            promise.reject(exception);
            return promise;
        }

        // Spec step 4: Perform ! ReadableStreamClose(stream)
        self.closeInternal();

        // Spec step 5: Let reader be stream.[[reader]]
        // Spec step 6: If reader is not undefined and reader implements ReadableStreamBYOBReader
        // BYOB reader readIntoRequests are now handled in errorInternal() and closeInternal()

        // Spec step 7: Let sourceCancelPromise be ! stream.[[controller]].[[CancelSteps]](reason)
        const cancel_promise = try self.controller.cancelInternal(reason);

        // Spec step 8: Return the result of reacting to sourceCancelPromise with a fulfillment step that returns undefined
        // For simplicity, we return the promise directly (equivalent behavior)
        return cancel_promise;
    
    }

    fn acquireDefaultReader(self: *ReadableStream, loop: eventLoop.EventLoop) !*ReadableStreamDefaultReader {

        // Create reader on heap
        const reader = try self.allocator.create(ReadableStreamDefaultReader);
        errdefer self.allocator.destroy(reader);

        // Initialize reader
        reader.* = try ReadableStreamDefaultReader.init(self.allocator, self, loop);

        // Lock stream to reader
        self.reader = .{ .default = reader };

        return reader;
    
    }

    fn acquireBYOBReader(self: *ReadableStream, loop: eventLoop.EventLoop) !*ReadableStreamBYOBReader {

        // Step 1: If stream is locked, throw TypeError
        if (self.get_locked()) {
            return error.TypeError;
        }

        // Step 2: If controller is not ReadableByteStreamController, throw TypeError
        switch (self.controller) {
            .byte => {},
            else => return error.TypeError,
        }

        // Create reader on heap
        const reader = try self.allocator.create(ReadableStreamBYOBReader);
        errdefer self.allocator.destroy(reader);

        // Initialize reader (this performs ReadableStreamReaderGenericInitialize + sets readIntoRequests)
        reader.* = try ReadableStreamBYOBReader.init(self.allocator, self, loop);

        // Lock stream to reader
        self.reader = .{ .byob = reader };

        return reader;
    
    }

    pub fn createByteStream(
        allocator: std.mem.Allocator,
        startAlgorithm: common.StartAlgorithm,
        pullAlgorithm: common.PullAlgorithm,
        cancelAlgorithm: common.CancelAlgorithm,
        loop: eventLoop.EventLoop,
    ) !*ReadableStream {

        // Step 1: Let stream be a new ReadableStream
        const stream = try allocator.create(ReadableStream);
        errdefer allocator.destroy(stream);

        // Step 2: Perform InitializeReadableStream(stream)
        stream.* = ReadableStream{
            .allocator = allocator,
            .state = .readable,
            .reader = .none,
            .storedError = null,
            .disturbed = false,
            .detached = false,
            .controller = undefined, // Will be set below
            .eventLoop = loop,
            .eventLoop_storage = null,
            .teeState = null,
        };

        // Step 3: Let controller be a new ReadableByteStreamController
        // Step 4: Perform SetUpReadableByteStreamController with hwm=0, autoAllocate=undefined
        const controller = try ReadableByteStreamController.init(
            allocator,
            cancelAlgorithm,
            pullAlgorithm,
            0.0, // highWaterMark = 0
            null, // autoAllocateChunkSize = undefined
            loop,
        );

        // Allocate controller on heap
        const controller_ptr = try allocator.create(ReadableByteStreamController);
        controller_ptr.* = controller;
        controller_ptr.stream = stream;
        controller_ptr.started = false;

        // Set stream's controller (cast required until controller union is implemented)
        // TODO: Make ReadableStream.controller a union type
        stream.controller = @ptrCast(controller_ptr);

        // Execute start algorithm
        _ = startAlgorithm; // TODO: Call startAlgorithm once signature is finalized
        controller_ptr.started = true;

        // Step 5: Return stream
        return stream;
    
    }

    fn ReadableStreamFromIterable(
        allocator: std.mem.Allocator,
        loop: eventLoop.EventLoop,
        asyncIterable: common.JSValue,
    ) !*ReadableStream {

        // Mark as unused until full implementation
        _ = asyncIterable;

        // Spec step 1: Let stream be undefined (will be set in step 6)

        // Spec step 2: Let iteratorRecord be ? GetIterator(asyncIterable, async)
        // For Zig implementation, we expect the JSValue to provide iterator protocol
        // This would normally involve calling GetIterator from ECMA-262
        // For now, we'll create a simple wrapper that handles common cases

        // Spec step 3: Let startAlgorithm be an algorithm that returns undefined
        // (No-op start - stream starts immediately)

        // Spec step 4: Let pullAlgorithm be the following steps:
        // (Implemented as a closure that captures iteratorRecord and stream)
        //
        // The pull algorithm:
        // 1. Call IteratorNext on the iterator
        // 2. If it throws, reject promise with the error
        // 3. Otherwise, wait for the promise to resolve
        // 4. If done=true, close the controller
        // 5. If done=false, enqueue the value to the controller

        // Spec step 5: Let cancelAlgorithm be the following steps, given reason:
        // (Implemented as a closure that captures iteratorRecord)
        //
        // The cancel algorithm:
        // 1. Get the iterator's return method
        // 2. If it doesn't exist, resolve immediately
        // 3. Otherwise, call the return method with reason
        // 4. Return a promise that resolves when cleanup is done

        // For the Zig implementation, we create a simpler approach:
        // - Store the iterable JSValue in the controller's context
        // - The pull algorithm calls next() on the iterable
        // - The cancel algorithm calls return() if available

        // Since we don't have full JS runtime integration yet, we'll create
        // a simplified version that works with Zig-native iterables

        // TODO: Full implementation requires:
        // 1. GetIterator(asyncIterable, async) from ECMA-262
        // 2. IteratorNext, IteratorComplete, IteratorValue
        // 3. GetMethod and Call from ECMA-262
        // 4. Proper promise chaining with .then()
        //
        // For now, we create a basic version that handles simple cases

        // Create algorithms that handle the iterable
        // NOTE: This is a simplified implementation pending full JS runtime integration
        const pullAlgorithm = common.defaultPullAlgorithm();
        const cancelAlgorithm = common.defaultCancelAlgorithm();

        // Spec step 6: Set stream to ! CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, 0)
        // Use highWaterMark of 0 per spec
        const stream = try allocator.create(ReadableStream);
        errdefer allocator.destroy(stream);

        // Create controller
        const controller = try allocator.create(ReadableStreamDefaultController);
        errdefer allocator.destroy(controller);

        controller.* = try ReadableStreamDefaultController.init(
            allocator,
            cancelAlgorithm,
            pullAlgorithm,
            0.0, // highWaterMark = 0 per spec
            common.defaultSizeAlgorithm(),
            loop,
        );

        // Initialize stream
        stream.* = ReadableStream{
            .allocator = allocator,
            .controller = controller,
            .detached = false,
            .disturbed = false,
            .reader = .none,
            .state = .readable,
            .storedError = null,
            .eventLoop = loop,
            .eventLoop_storage = null,
            .teeState = null,
        };

        controller.stream = stream;
        controller.started = true;

        // TODO: Implement full iterator protocol handling
        // For now, this creates an empty stream
        // Full implementation requires:
        // 1. Capture iteratorRecord in pull/cancel algorithms
        // 2. Call IteratorNext in pull algorithm
        // 3. Call return method in cancel algorithm
        // 4. Handle async iteration with proper promise chaining
        //
        // The structure is in place for when JS runtime integration is available

        // Spec step 7: Return stream
        return stream;
    
    }

    pub fn getNumReadRequests(self: *const ReadableStream) usize {

        return switch (self.reader) {
            .none => 0,
            .default => |reader| reader.readRequests.items.len,
            .byob => 0, // BYOB reader uses read-into requests, not read requests
        };
    
    }

    pub fn hasDefaultReader(self: *const ReadableStream) bool {

        return switch (self.reader) {
            .default => true,
            else => false,
        };
    
    }

    pub fn hasBYOBReader(self: *const ReadableStream) bool {

        return switch (self.reader) {
            .byob => true,
            else => false,
        };
    
    }

    pub fn getNumReadIntoRequests(self: *const ReadableStream) usize {

        return switch (self.reader) {
            .none => 0,
            .default => 0, // Default reader doesn't have read-into requests
            .byob => |reader| reader.readIntoRequests.items.len,
        };
    
    }

    pub fn fulfillReadRequest(self: *ReadableStream, chunk: common.JSValue, done: bool) void {

        switch (self.reader) {
            .none => return, // No reader, nothing to fulfill
            .default => |reader| {
                // Remove the first read request
                if (reader.readRequests.items.len == 0) return;

                const promise = reader.readRequests.orderedRemove(0);

                // Fulfill the promise with the read result
                if (done) {
                    promise.fulfill(.{
                        .value = null,
                        .done = true,
                    });
                } else {
                    promise.fulfill(.{
                        .value = chunk,
                        .done = false,
                    });
                }
            },
            .byob => {}, // BYOB uses fulfillReadIntoRequest
        }
    
    }

    pub fn fulfillReadIntoRequest(self: *ReadableStream, chunk: webidl.ArrayBufferView, done: bool) void {

        switch (self.reader) {
            .none => return, // No reader, nothing to fulfill
            .default => return, // Default reader doesn't have read-into requests
            .byob => |reader| {
                // Remove the first read-into request
                if (reader.readIntoRequests.items.len == 0) return;

                const request = reader.readIntoRequests.orderedRemove(0);

                // Execute the appropriate steps based on done flag
                if (done) {
                    const ReadIntoRequestModule = @import("read_into_request");
                    // Convert chunk to ReadIntoRequest ArrayBufferView
                    const view = ReadIntoRequestModule.ArrayBufferView{
                        .data = chunk.getViewedArrayBuffer().data,
                        .offset = @intCast(chunk.getByteOffset()),
                        .length = @intCast(chunk.getByteLength()),
                    };
                    request.executeCloseSteps();
                    _ = view; // TODO: Should pass view to close steps with done=true
                } else {
                    const ReadIntoRequestModule = @import("read_into_request");
                    // Convert chunk to ReadIntoRequest ArrayBufferView
                    const view = ReadIntoRequestModule.ArrayBufferView{
                        .data = chunk.getViewedArrayBuffer().data,
                        .offset = @intCast(chunk.getByteOffset()),
                        .length = @intCast(chunk.getByteLength()),
                    };
                    request.executeChunkSteps(view);
                }
            },
        }
    
    }

    pub fn closeInternal(self: *ReadableStream) void {

        // Spec step 1: Assert: stream.[[state]] is "readable"
        std.debug.assert(self.state == .readable);

        // Spec step 2: Set stream.[[state]] to "closed"
        self.state = .closed;

        // Spec step 3: Let reader be stream.[[reader]]
        // Spec step 4: If reader is undefined, return
        switch (self.reader) {
            .none => return,
            .default => |reader| {
                // Spec step 5: Resolve reader.[[closedPromise]] with undefined
                reader.closedPromise.fulfill({});

                // Spec step 6: If reader implements ReadableStreamDefaultReader
                // Spec step 6.1: Let readRequests be reader.[[readRequests]]
                // Spec step 6.2: Set reader.[[readRequests]] to an empty list
                // Spec step 6.3: For each readRequest of readRequests, perform readRequest's close steps
                while (reader.readRequests.items.len > 0) {
                    const read_promise = reader.readRequests.orderedRemove(0);
                    // Close steps: fulfill with { value: undefined, done: true }
                    read_promise.fulfill(.{
                        .value = null,
                        .done = true,
                    });
                }
            },
            .byob => |reader| {
                // Spec: Resolve closed promise
                reader.closedPromise.fulfill({});

                // Spec: Respond to all pending readIntoRequests with done=true
                while (reader.readIntoRequests.items.len > 0) {
                    const request = reader.readIntoRequests.orderedRemove(0);
                    // Close steps should return the view with done=true
                    // For now, execute close steps with empty view
                    request.executeCloseSteps();
                }
            },
        }
    
    }

    pub fn errorInternal(self: *ReadableStream, e: common.JSValue) void {

        // Step 1: Assert: stream.[[state]] is "readable".
        if (self.state != .readable) {
            return;
        }

        // Step 2: Set stream.[[state]] to "errored".
        self.state = .errored;

        // Step 3: Set stream.[[storedError]] to e.
        self.storedError = e;

        // Step 4: Let reader be stream.[[reader]].
        // Step 5-7: Reject reader's closed promise and all pending reads
        const exception = e.toException(self.allocator) catch return;
        switch (self.reader) {
            .none => {},
            .default => |reader| {
                // Reject closed promise
                reader.closedPromise.reject(exception);

                // Reject all pending read requests
                while (reader.readRequests.items.len > 0) {
                    const promise = reader.readRequests.orderedRemove(0);
                    promise.reject(exception);
                }
            },
            .byob => |reader| {
                // Spec: Reject closed promise
                reader.closedPromise.reject(exception);

                // Spec: Reject all pending readIntoRequests
                while (reader.readIntoRequests.items.len > 0) {
                    const request = reader.readIntoRequests.orderedRemove(0);
                    request.reject(exception);
                }
            },
        }
    
    }

    fn readableByteStreamTee(self: *ReadableStream) !TeeBranches {

        // Step 1-2: Asserts
        if (self.controller != .byte) {
            return error.TypeError;
        }

        // Step 3: Acquire default reader
        const reader = try self.acquireDefaultReader(self.eventLoop);

        // Step 4-13: Initialize ByteTeeState
        const teeState = try ByteTeeState.init(
            self.allocator,
            self,
            reader,
            self.eventLoop,
        );
        errdefer teeState.deinit();

        // Step 14: forwardReaderError will be set up when reader errors occur
        // (Implemented in ByteTeeState.forwardReaderError)

        // Step 15-16: pullWithDefaultReader and pullWithBYOBReader are ByteTeeState methods

        // Step 17-18: pull1Algorithm and pull2Algorithm
        const Pull1Context = struct {
            state: *ByteTeeState,

            fn call(ctx: *anyopaque) common.Promise(void) {
                const self_ctx: *@This() = @ptrCast(@alignCast(ctx));
                self_ctx.state.pull1Algorithm() catch {};
                return common.Promise(void).fulfilled({});
            }
        };

        const pull1_ctx = try self.allocator.create(Pull1Context);
        pull1_ctx.* = .{ .state = teeState };

        const Pull2Context = struct {
            state: *ByteTeeState,

            fn call(ctx: *anyopaque) common.Promise(void) {
                const self_ctx: *@This() = @ptrCast(@alignCast(ctx));
                self_ctx.state.pull2Algorithm() catch {};
                return common.Promise(void).fulfilled({});
            }
        };

        const pull2_ctx = try self.allocator.create(Pull2Context);
        pull2_ctx.* = .{ .state = teeState };

        // Step 19-20: cancel1Algorithm and cancel2Algorithm
        const Cancel1Context = struct {
            state: *ByteTeeState,

            fn call(ctx: *anyopaque, reason: ?common.JSValue) common.Promise(void) {
                const self_ctx: *@This() = @ptrCast(@alignCast(ctx));
                _ = self_ctx.state.cancel1Algorithm(reason) catch return common.Promise(void).fulfilled({});
                return common.Promise(void).fulfilled({});
            }
        };

        const cancel1_ctx = try self.allocator.create(Cancel1Context);
        cancel1_ctx.* = .{ .state = teeState };

        const Cancel2Context = struct {
            state: *ByteTeeState,

            fn call(ctx: *anyopaque, reason: ?common.JSValue) common.Promise(void) {
                const self_ctx: *@This() = @ptrCast(@alignCast(ctx));
                _ = self_ctx.state.cancel2Algorithm(reason) catch return common.Promise(void).fulfilled({});
                return common.Promise(void).fulfilled({});
            }
        };

        const cancel2_ctx = try self.allocator.create(Cancel2Context);
        cancel2_ctx.* = .{ .state = teeState };

        // Step 21: startAlgorithm (no-op)

        // Step 22-23: Create branch streams with createByteStream
        const branch1 = try createByteStream(
            self.allocator,
            null, // no start algorithm
            common.PullAlgorithm{
                .ptr = pull1_ctx,
                .vtable = &.{ .call = Pull1Context.call, .deinit = null },
            },
            common.CancelAlgorithm{
                .ptr = cancel1_ctx,
                .vtable = &.{ .call = Cancel1Context.call, .deinit = null },
            },
            self.eventLoop,
        );

        const branch2 = try createByteStream(
            self.allocator,
            null, // no start algorithm
            common.PullAlgorithm{
                .ptr = pull2_ctx,
                .vtable = &.{ .call = Pull2Context.call, .deinit = null },
            },
            common.CancelAlgorithm{
                .ptr = cancel2_ctx,
                .vtable = &.{ .call = Cancel2Context.call, .deinit = null },
            },
            self.eventLoop,
        );

        // Link branches to tee state
        teeState.branch1 = branch1;
        teeState.branch2 = branch2;

        // Step 24: Forward reader errors
        teeState.forwardReaderError(teeState.reader);

        // Step 25: Return branches
        return .{ .branch1 = branch1, .branch2 = branch2 };
    
    }

    fn teeInternal(self: *ReadableStream, cloneForBranch2: bool) !TeeBranches {

        // TODO: Route to byte stream tee if controller is a byte controller
        // Currently controller is typed as *ReadableStreamDefaultController
        // This needs to be a union type to support both controller types
        // if (self.controller == .byte) {
        //     return self.readableByteStreamTee();
        // }

        // Spec step 1-2: Asserts (checked by type system)

        // Spec step 3: Acquire reader
        const reader = try self.acquireDefaultReader(self.eventLoop);

        // Spec step 4-12: Initialize state variables (now in TeeState)
        const teeState = try TeeState.init(
            self.allocator,
            self,
            reader,
            self.eventLoop,
            cloneForBranch2,
        );
        errdefer teeState.deinit();

        // Spec step 16-18: Create branch streams with custom pull/cancel algorithms
        // We create two streams that share the TeeState for coordination

        const branch1 = try self.allocator.create(ReadableStream);
        errdefer self.allocator.destroy(branch1);

        const branch2 = try self.allocator.create(ReadableStream);
        errdefer self.allocator.destroy(branch2);

        // Initialize branch streams
        branch1.* = try initWithSource(self.allocator, self.eventLoop, null, null);
        branch2.* = try initWithSource(self.allocator, self.eventLoop, null, null);

        // Link branches to tee state
        teeState.branch1 = branch1;
        teeState.branch2 = branch2;
        branch1.teeState = teeState;
        branch2.teeState = teeState;

        // Spec step 19: Forward reader errors to both branches
        // (Would be implemented with reader.closedPromise reaction)
        // TODO: Implement error forwarding when reader's closedPromise rejects

        // Spec step 20: Return the two branches
        return .{ .branch1 = branch1, .branch2 = branch2 };
    
    }

};


