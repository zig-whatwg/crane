// Auto-generated by zoop-codegen
// DO NOT EDIT - changes will be overwritten
//
// This file was generated from the source file with the same name.
// Class definitions have been enhanced with:
//   - Inherited methods from parent classes
//   - Property getters and setters
//   - Optimized field layouts

//! ReadableByteStreamController class per WHATWG Streams Standard
//!
//! Spec: https://streams.spec.whatwg.org/#rbs-controller-class
//! IDL: specs/streams.idl lines 105-113
//!
//! Controls a ReadableStream with type "bytes" for efficient binary data streaming.

const std = @import("std");
const webidl = @import("webidl");
const common = @import("common");
const QueueWithSizes = @import("queue_with_sizes").QueueWithSizes;
const ReadableStreamBYOBRequest = @import("readable_stream_byob_request").ReadableStreamBYOBRequest;
const ReadableStreamModule = @import("readable_stream");
const ReadableStream = ReadableStreamModule.ReadableStream;
const event_loop = @import("event_loop");
const AsyncPromise = @import("async_promise").AsyncPromise;
const PullIntoDescriptorModule = @import("pull_into_descriptor");
const PullIntoDescriptor = PullIntoDescriptorModule.PullIntoDescriptor;
const ArrayBuffer = PullIntoDescriptorModule.ArrayBuffer;
const ViewConstructor = PullIntoDescriptorModule.ViewConstructor;
const ReaderType = PullIntoDescriptorModule.ReaderType;
const view_construction = @import("view_construction");
const ReadRequest = @import("read_request").ReadRequest;
const ReadIntoRequest = @import("read_into_request").ReadIntoRequest;

/// Convert webidl.ArrayBuffer to internal ArrayBuffer
/// This creates an internal ArrayBuffer that wraps the webidl ArrayBuffer's data
fn convertWebIDLArrayBuffer(allocator: std.mem.Allocator, webidl_buffer: webidl.ArrayBuffer) !*ArrayBuffer {
    const internal_buffer = try allocator.create(ArrayBuffer);
    internal_buffer.* = .{
        .data = webidl_buffer.data,
        .byte_length = webidl_buffer.data.len,
        .detached = webidl_buffer.detached,
    };
    return internal_buffer;
}

/// Convert internal ArrayBuffer to webidl.ArrayBuffer
/// This creates a webidl ArrayBuffer that wraps the internal ArrayBuffer's data
fn convertToWebIDLArrayBuffer(allocator: std.mem.Allocator, internal_buffer: *ArrayBuffer) !*webidl.ArrayBuffer {
    const webidl_buffer = try allocator.create(webidl.ArrayBuffer);
    webidl_buffer.* = .{
        .data = internal_buffer.data,
        .detached = internal_buffer.detached,
    };
    return webidl_buffer;
}

/// Byte stream queue entry per WHATWG Streams Standard § 4.7.2
///
/// Represents a queued chunk in a byte stream with its buffer and byte range.
const ByteStreamQueueEntry = struct {
    /// The ArrayBuffer containing the queued bytes
    buffer: *ArrayBuffer,
    /// Byte offset into the buffer where this chunk starts
    byte_offset: u64,
    /// Length in bytes of this chunk
    byte_length: u64,
};
/// ReadableByteStreamController zoop class
/// 
/// IDL:
/// ```webidl
/// [Exposed=*]
/// interface ReadableByteStreamController {
/// readonly attribute ReadableStreamBYOBRequest? byobRequest;
/// readonly attribute unrestricted double? desiredSize;
/// 
/// undefined close();
/// undefined enqueue(ArrayBufferView chunk);
/// undefined error(optional any e);
/// };
/// ```
pub const ReadableByteStreamController = struct {
    allocator: std.mem.Allocator,
    /// [[autoAllocateChunkSize]]: Size for auto-allocated buffers
    auto_allocate_chunk_size: ?u64,
    /// [[byobRequest]]: Current BYOB request (or null)
    byob_request: ?*ReadableStreamBYOBRequest,
    /// [[cancelAlgorithm]]: Promise-returning algorithm for cancelation
    cancel_algorithm: common.CancelAlgorithm,
    /// [[closeRequested]]: boolean - stream closed by source but has queued chunks
    close_requested: bool,
    /// [[pullAgain]]: boolean - pull requested but previous pull still executing
    pull_again: bool,
    /// [[pullAlgorithm]]: Promise-returning algorithm for pulling data
    pull_algorithm: common.PullAlgorithm,
    /// [[pulling]]: boolean - pull algorithm currently executing
    pulling: bool,
    /// [[pendingPullIntos]]: List of pending pull-into descriptors
    pending_pull_intos: std.ArrayList(*PullIntoDescriptor),
    /// [[queue]]: List of byte stream queue entries
    queue: std.ArrayList(ByteStreamQueueEntry),
    /// [[queueTotalSize]]: Total size of all byte chunks in queue
    queue_total_size: f64,
    /// [[started]]: boolean - underlying source has finished starting
    started: bool,
    /// [[strategyHWM]]: High water mark for backpressure
    strategy_hwm: f64,
    /// [[stream]]: The ReadableStream instance controlled
    stream: ?*ReadableStream,
    /// Event loop for async operations
    event_loop: event_loop.EventLoop,

    /// Initialize a new controller (internal - not exposed via WebIDL)
    pub fn init(
        allocator: std.mem.Allocator,
        cancel_algorithm: common.CancelAlgorithm,
        pull_algorithm: common.PullAlgorithm,
        strategy_hwm: f64,
        auto_allocate_chunk_size: ?u64,
        loop: event_loop.EventLoop,
    ) ReadableByteStreamController {
        return .{
            .allocator = allocator,
            .auto_allocate_chunk_size = auto_allocate_chunk_size,
            .byob_request = null,
            .cancel_algorithm = cancel_algorithm,
            .close_requested = false,
            .pull_again = false,
            .pull_algorithm = pull_algorithm,
            .pulling = false,
            .pending_pull_intos = .{},
            .queue = .{},
            .queue_total_size = 0.0,
            .started = false,
            .strategy_hwm = strategy_hwm,
            .stream = null,
            .event_loop = loop,
        };
    }
    pub fn deinit(self: *ReadableByteStreamController) void {
        self.queue.deinit(self.allocator);
        self.pending_pull_intos.deinit(self.allocator);
        if (self.byob_request) |req| {
            req.deinit();
            self.allocator.destroy(req);
        }
    }
    /// Returns the current BYOB request, or null.
    /// 
    /// IDL: readonly attribute ReadableStreamBYOBRequest? byobRequest;
    /// 
    /// Spec algorithm: § 4.10.10 "The byobRequest getter steps are:"
    pub fn get_byobRequest(self: *const ReadableByteStreamController) !?*ReadableStreamBYOBRequest {
        // Step 1: Return ! ReadableByteStreamControllerGetBYOBRequest(this).
        // Note: Cast away const since getBYOBRequest may need to create a request
        return try @constCast(self).getBYOBRequest();
    }
    /// Returns the desired size to fill the stream's internal queue.
    /// 
    /// IDL: readonly attribute unrestricted double? desiredSize;
    /// 
    /// Spec algorithm: § 4.7.3 "The desiredSize getter steps are:"
    pub fn get_desiredSize(self: *const ReadableByteStreamController) ?f64 {
        // Step 1: Return ! ReadableByteStreamControllerGetDesiredSize(this).
        return self.calculateDesiredSize();
    }
    /// Calculate desired size (internal helper)
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerGetDesiredSize(controller)"
    fn calculateDesiredSize(self: *const ReadableByteStreamController) ?f64 {
        // If stream is closed, return 0
        if (self.close_requested and self.queue.items.len == 0) {
            return 0.0;
        }

        // Return highWaterMark - queueTotalSize
        return self.strategy_hwm - self.queue_total_size;
    }
    /// Closes the controlled readable stream.
    /// 
    /// IDL: undefined close();
    /// 
    /// Spec algorithm: § 4.7.3 "The close() method steps are:"
    pub fn call_close(self: *ReadableByteStreamController) !void {
        // Step 1: If this.[[closeRequested]] is true, throw a TypeError exception.
        if (self.close_requested) {
            return error.TypeError;
        }

        // Step 2: If this.[[stream]].[[state]] is not "readable", throw a TypeError exception.
        // (Simplified for now - full implementation would check stream state)

        // Step 3: Perform ? ReadableByteStreamControllerClose(this).
        self.closeInternal();
    }
    /// Enqueues the given chunk in the controlled readable stream.
    /// 
    /// IDL: undefined enqueue(ArrayBufferView chunk);
    /// 
    /// Spec algorithm: § 4.7.3 "The enqueue(chunk) method steps are:"
    pub fn call_enqueue(self: *ReadableByteStreamController, chunk: webidl.ArrayBufferView) !void {
        // Step 1: If chunk.[[ByteLength]] is 0, throw a TypeError exception.
        // TODO: Check byte length when webidl provides the API

        // Step 2: If chunk.[[ViewedArrayBuffer]].[[ArrayBufferByteLength]] is 0,
        //         throw a TypeError exception.
        // TODO: Check buffer byte length when webidl provides the API

        // Step 3: If this.[[closeRequested]] is true, throw a TypeError exception.
        if (self.close_requested) {
            return error.TypeError;
        }

        // Step 4: If this.[[stream]].[[state]] is not "readable", throw a TypeError exception.
        // (Simplified for now - full implementation would check stream state)

        // Step 5: Return ! ReadableByteStreamControllerEnqueue(this, chunk).
        try self.enqueueInternal(chunk);
    }
    /// Errors the controlled readable stream.
    /// 
    /// IDL: undefined error(optional any e);
    /// 
    /// Spec algorithm: § 4.7.3 "The error(e) method steps are:"
    pub fn call_error(self: *ReadableByteStreamController, e: webidl.Optional(webidl.JSValue)) void {
        const error_value = if (e.was_passed)
            common.JSValue.fromWebIDL(e.value)
        else
            common.JSValue.fromWebIDL(webidl.JSValue{ .undefined = {} });

        // Step 1: Perform ! ReadableByteStreamControllerError(this, e).
        self.errorInternal(error_value);
    }
    /// Close the controller
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerClose(controller)"
    fn closeInternal(self: *ReadableByteStreamController) void {
        // Step 1: Let stream be controller.[[stream]].
        // TODO: Get stream reference

        // Step 2: If controller.[[closeRequested]] is true or stream.[[state]] is not "readable", return.
        if (self.close_requested) {
            return;
        }
        // TODO: Check stream state (requires stream reference)

        // Step 3: If controller.[[queueTotalSize]] > 0,
        if (self.queue_total_size > 0) {
            // Step 3.1: Set controller.[[closeRequested]] to true.
            self.close_requested = true;

            // Step 3.2: Return.
            return;
        }

        // Step 4: If controller.[[pendingPullIntos]] is not empty,
        if (self.pending_pull_intos.items.len > 0) {
            // Step 4.1: Let firstPendingPullInto be controller.[[pendingPullIntos]][0].
            const first_pending = self.pending_pull_intos.items[0];

            // Step 4.2: If the remainder after dividing firstPendingPullInto's bytes filled
            //           by firstPendingPullInto's element size is not 0,
            if (first_pending.bytes_filled % first_pending.element_size != 0) {
                // Step 4.2.1: Let e be a new TypeError exception.
                const e = common.JSValue{ .string = "Incomplete byte fill in pending pull-into" };

                // Step 4.2.2: Perform ! ReadableByteStreamControllerError(controller, e).
                self.errorInternal(e);

                // Step 4.2.3: Throw e.
                // Note: In Zig, we just return since errorInternal handles the error state
                return;
            }
        }

        // Step 5: Perform ! ReadableByteStreamControllerClearAlgorithms(controller).
        self.clearAlgorithms();

        // Step 6: Perform ! ReadableStreamClose(stream).
        // TODO: Close the stream (requires stream reference)
    }
    /// Enqueue a chunk
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerEnqueue(controller, chunk)"
    fn enqueueInternal(self: *ReadableByteStreamController, chunk: webidl.ArrayBufferView) !void {
        // Step 1: Let stream be controller.[[stream]].
        const stream = self.stream orelse return error.NoStream;

        // Step 2: If controller.[[closeRequested]] is true or stream.[[state]] is not "readable", return.
        if (self.close_requested or stream.state != .readable) {
            return;
        }

        // Step 3-5: Extract buffer, byteOffset, byteLength from chunk using webidl 0.7.0 APIs
        const buffer = chunk.getViewedArrayBuffer();
        const byte_offset: u64 = @intCast(chunk.getByteOffset());
        const byte_length: u64 = @intCast(chunk.getByteLength());

        // Step 6: If ! IsDetachedBuffer(buffer) is true, throw a TypeError exception.
        if (buffer.isDetached()) {
            return error.TypeError;
        }

        // Step 7: Let transferredBuffer be ? TransferArrayBuffer(buffer).
        // Convert webidl.ArrayBuffer to internal ArrayBuffer first
        const internal_buffer = try convertWebIDLArrayBuffer(self.allocator, buffer.*);
        const transferred_buffer = try internal_buffer.transfer();
        const transferred_buffer_ptr = try self.allocator.create(ArrayBuffer);
        transferred_buffer_ptr.* = transferred_buffer;
        // Clean up the temporary internal buffer (now detached)
        self.allocator.destroy(internal_buffer);

        // Step 8: If controller.[[pendingPullIntos]] is not empty,
        if (self.pending_pull_intos.items.len > 0) {
            // Step 8.1: Let firstPendingPullInto be controller.[[pendingPullIntos]][0].
            const first_pending_pull_into = self.pending_pull_intos.items[0];

            // Step 8.2: If ! IsDetachedBuffer(firstPendingPullInto's buffer) is true, throw a TypeError exception.
            if (first_pending_pull_into.buffer.isDetached()) {
                return error.TypeError;
            }

            // Step 8.3: Perform ! ReadableByteStreamControllerInvalidateBYOBRequest(controller).
            self.invalidateBYOBRequest();

            // Step 8.4: Set firstPendingPullInto's buffer to ! TransferArrayBuffer(firstPendingPullInto's buffer).
            const old_buffer = first_pending_pull_into.buffer;
            const transferred = try old_buffer.transfer();
            const transferred_ptr = try self.allocator.create(ArrayBuffer);
            transferred_ptr.* = transferred;
            first_pending_pull_into.buffer = transferred_ptr;
            self.allocator.destroy(old_buffer);

            // Step 8.5: If firstPendingPullInto's reader type is "none", perform ? ReadableByteStreamControllerEnqueueDetachedPullIntoToQueue(controller, firstPendingPullInto).
            if (first_pending_pull_into.reader_type == .none) {
                try self.enqueueDetachedPullIntoToQueue(first_pending_pull_into);
            }
        }

        // Step 9: If ! ReadableStreamHasDefaultReader(stream) is true,
        if (stream.hasDefaultReader()) {
            // Step 9.1: Perform ! ReadableByteStreamControllerProcessReadRequestsUsingQueue(controller).
            try self.processReadRequestsUsingQueue();

            // Step 9.2: If ! ReadableStreamGetNumReadRequests(stream) is 0,
            if (stream.getNumReadRequests() == 0) {
                // Step 9.2.1: Assert: controller.[[pendingPullIntos]] is empty.
                // (Assertion)

                // Step 9.2.2: Perform ! ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength).
                try self.enqueueChunkToQueue(transferred_buffer_ptr, byte_offset, byte_length);
            } else {
                // Step 9.3: Otherwise,
                // Step 9.3.1: Assert: controller.[[queue]] is empty.
                // (Assertion)

                // Step 9.3.2: If controller.[[pendingPullIntos]] is not empty,
                if (self.pending_pull_intos.items.len > 0) {
                    // Step 9.3.2.1: Assert: controller.[[pendingPullIntos]][0]'s reader type is "default".
                    // Step 9.3.2.2: Perform ! ReadableByteStreamControllerShiftPendingPullInto(controller).
                    _ = self.shiftPendingPullInto();
                }

                // Step 9.3.3: Let transferredView be ! Construct(%Uint8Array%, « transferredBuffer, byteOffset, byteLength »).
                const transferred_view = try view_construction.constructView(
                    ViewConstructor.uint8_array,
                    transferred_buffer_ptr,
                    byte_offset,
                    byte_length,
                );

                // Step 9.3.4: Perform ! ReadableStreamFulfillReadRequest(stream, transferredView, false).
                // TODO: Convert ArrayBufferView to JSValue
                _ = transferred_view;
                stream.fulfillReadRequest(common.JSValue{ .object = {} }, false);
            }
        } else if (stream.hasBYOBReader()) {
            // Step 10: Otherwise, if ! ReadableStreamHasBYOBReader(stream) is true,
            // Step 10.1: Perform ! ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength).
            try self.enqueueChunkToQueue(transferred_buffer_ptr, byte_offset, byte_length);

            // Step 10.2: Let filledPullIntos be the result of performing ! ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller).
            var filled_pull_intos = try self.processPullIntoDescriptorsUsingQueue();
            defer filled_pull_intos.deinit(self.allocator);

            // Step 10.3: For each filledPullInto of filledPullIntos,
            for (filled_pull_intos.items) |filled_pull_into| {
                // Step 10.3.1: Perform ! ReadableByteStreamControllerCommitPullIntoDescriptor(stream, filledPullInto).
                try self.commitPullIntoDescriptor(filled_pull_into);
            }
        } else {
            // Step 11: Otherwise,
            // Step 11.1: Assert: ! IsReadableStreamLocked(stream) is false.
            // (Assertion)

            // Step 11.2: Perform ! ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength).
            try self.enqueueChunkToQueue(transferred_buffer_ptr, byte_offset, byte_length);
        }

        // Step 12: Perform ! ReadableByteStreamControllerCallPullIfNeeded(controller).
        self.callPullIfNeeded();
    }
    /// Error the controller
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerError(controller, e)"
    fn errorInternal(self: *ReadableByteStreamController, e: common.JSValue) void {
        // Step 1: Let stream be controller.[[stream]].
        // Step 2: If stream.[[state]] is not "readable", return.
        // (Not implemented yet - requires stream reference)

        // Step 3: Perform ! ReadableByteStreamControllerClearPendingPullIntos(controller).
        self.clearPendingPullIntos();

        // Step 4: Perform ! ResetQueue(controller).
        self.queue.clearRetainingCapacity();
        self.queue_total_size = 0.0;

        // Step 5: Perform ! ReadableByteStreamControllerClearAlgorithms(controller).
        self.clearAlgorithms();

        // Step 6: Perform ! ReadableStreamError(stream, e).
        // (Would error the stream here - not implemented yet)
        _ = e; // Will be used when stream error is implemented
    }
    /// Clear all algorithm references
    /// 
    /// Spec: § 4.7.4 "ReadableByteStreamControllerClearAlgorithms(controller)"
    fn clearAlgorithms(self: *ReadableByteStreamController) void {
        // Reset algorithms to defaults to allow GC
        self.cancel_algorithm = common.defaultCancelAlgorithm();
        self.pull_algorithm = common.defaultPullAlgorithm();
    }
    /// Enqueue a chunk to the byte stream queue
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerEnqueueChunkToQueue(controller, buffer, byteOffset, byteLength)"
    fn enqueueChunkToQueue(
        self: *ReadableByteStreamController,
        buffer: *ArrayBuffer,
        byte_offset: u64,
        byte_length: u64,
    ) !void {
        // Step 1: Append a new readable byte stream queue entry with buffer `buffer`,
        //         byte offset `byteOffset`, and byte length `byteLength` to controller.[[queue]].
        try self.queue.append(self.allocator, .{
            .buffer = buffer,
            .byte_offset = byte_offset,
            .byte_length = byte_length,
        });

        // Step 2: Set controller.[[queueTotalSize]] to controller.[[queueTotalSize]] + byteLength.
        self.queue_total_size += @as(f64, @floatFromInt(byte_length));
    }
    /// Enqueue cloned chunk to queue
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerEnqueueClonedChunkToQueue(controller, buffer, byteOffset, byteLength)"
    fn enqueueClonedChunkToQueue(
        self: *ReadableByteStreamController,
        buffer: *ArrayBuffer,
        byte_offset: u64,
        byte_length: u64,
    ) !void {
        // Step 1: Let cloneResult be CloneArrayBuffer(buffer, byteOffset, byteLength, %ArrayBuffer%).
        const clone_result = buffer.clone(
            self.allocator,
            @as(usize, @intCast(byte_offset)),
            @as(usize, @intCast(byte_length)),
        ) catch |err| {
            // Step 2: If cloneResult is an abrupt completion,
            // Step 2.1: Perform ! ReadableByteStreamControllerError(controller, cloneResult.[[Value]]).
            const error_value = common.JSValue{ .string = "Failed to clone buffer" };
            self.errorInternal(error_value);

            // Step 2.2: Return cloneResult.
            return err;
        };

        // Step 3: Perform ! ReadableByteStreamControllerEnqueueChunkToQueue(controller, cloneResult.[[Value]], 0, byteLength).
        // Note: We need to allocate the cloned buffer on the heap
        const cloned_buffer = try self.allocator.create(ArrayBuffer);
        cloned_buffer.* = clone_result;

        try self.enqueueChunkToQueue(cloned_buffer, 0, byte_length);
    }
    /// Enqueue detached pull-into to queue
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerEnqueueDetachedPullIntoToQueue(controller, pullIntoDescriptor)"
    fn enqueueDetachedPullIntoToQueue(
        self: *ReadableByteStreamController,
        pull_into_descriptor: *PullIntoDescriptor,
    ) !void {
        // Step 1: Assert: pullIntoDescriptor's reader type is "none".
        // (Assertion - caller ensures this)

        // Step 2: If pullIntoDescriptor's bytes filled > 0,
        if (pull_into_descriptor.bytes_filled > 0) {
            // perform ? ReadableByteStreamControllerEnqueueClonedChunkToQueue(
            //     controller, pullIntoDescriptor's buffer,
            //     pullIntoDescriptor's byte offset, pullIntoDescriptor's bytes filled).
            try self.enqueueClonedChunkToQueue(
                pull_into_descriptor.buffer,
                pull_into_descriptor.byte_offset,
                pull_into_descriptor.bytes_filled,
            );
        }

        // Step 3: Perform ! ReadableByteStreamControllerShiftPendingPullInto(controller).
        _ = self.shiftPendingPullInto();
    }
    /// Invalidate the current BYOB request
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerInvalidateBYOBRequest(controller)"
    fn invalidateBYOBRequest(self: *ReadableByteStreamController) void {
        // Step 1: If controller.[[byobRequest]] is null, return.
        if (self.byob_request) |req| {
            // Step 2: Set controller.[[byobRequest]].[[controller]] to undefined.
            req.controller = null;

            // Step 3: Set controller.[[byobRequest]].[[view]] to null.
            req.view = null;

            // Step 4: Set controller.[[byobRequest]] to null.
            self.byob_request = null;

            // Clean up memory (not in spec, but required for Zig's explicit memory management)
            // Note: In browsers, the invalidated request object is garbage collected.
            // User code should access requests only through controller.byobRequest getter.
            req.deinit();
            self.allocator.destroy(req);
        }
    }
    /// Clear all pending pull-into descriptors
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerClearPendingPullIntos(controller)"
    fn clearPendingPullIntos(self: *ReadableByteStreamController) void {
        // Step 1: Perform ! ReadableByteStreamControllerInvalidateBYOBRequest(controller).
        self.invalidateBYOBRequest();

        // Step 2: Set controller.[[pendingPullIntos]] to a new empty list.
        // Note: We use clearRetainingCapacity to avoid reallocation
        self.pending_pull_intos.clearRetainingCapacity();
    }
    /// Get the BYOB request for this controller
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerGetBYOBRequest(controller)"
    fn getBYOBRequest(self: *ReadableByteStreamController) !?*ReadableStreamBYOBRequest {
        // Step 1: If controller.[[byobRequest]] is null and controller.[[pendingPullIntos]] is not empty,
        if (self.byob_request == null and self.pending_pull_intos.items.len > 0) {
            // Step 1.1: Let firstDescriptor be controller.[[pendingPullIntos]][0].
            const first_descriptor = self.pending_pull_intos.items[0];

            // Step 1.2: Let view be ! Construct(%Uint8Array%, « firstDescriptor's buffer,
            //           firstDescriptor's byte offset + firstDescriptor's bytes filled,
            //           firstDescriptor's byte length − firstDescriptor's bytes filled »).
            const view_byte_offset = first_descriptor.byte_offset + first_descriptor.bytes_filled;
            const view_byte_length = first_descriptor.byte_length - first_descriptor.bytes_filled;

            // Construct Uint8Array view using webidl 0.7.0
            // Convert internal ArrayBuffer to webidl.ArrayBuffer for view construction
            const webidl_buffer = try convertToWebIDLArrayBuffer(self.allocator, first_descriptor.buffer);
            defer self.allocator.destroy(webidl_buffer);

            const Uint8ArrayType = webidl.TypedArray(u8);
            const uint8_view = try Uint8ArrayType.init(
                webidl_buffer,
                view_byte_offset,
                view_byte_length, // For Uint8Array, length in elements = length in bytes
            );
            const view = webidl.ArrayBufferView{ .uint8_array = uint8_view };

            // Step 1.3: Let byobRequest be a new ReadableStreamBYOBRequest.
            const byob_request = try self.allocator.create(ReadableStreamBYOBRequest);
            errdefer self.allocator.destroy(byob_request);

            // Step 1.4: Set byobRequest.[[controller]] to controller.
            // Step 1.5: Set byobRequest.[[view]] to view.
            byob_request.* = ReadableStreamBYOBRequest.init(
                self.allocator,
                self,
                view,
            );

            // Step 1.6: Set controller.[[byobRequest]] to byobRequest.
            self.byob_request = byob_request;
        }

        // Step 2: Return controller.[[byobRequest]].
        return self.byob_request;
    }
    /// Fill head pull-into descriptor with bytes
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, size, pullIntoDescriptor)"
    fn fillHeadPullIntoDescriptor(
        self: *ReadableByteStreamController,
        size: u64,
        pull_into_descriptor: *PullIntoDescriptor,
    ) void {
        // Step 1: Assert: either controller.[[pendingPullIntos]] is empty,
        //         or controller.[[pendingPullIntos]][0] is pullIntoDescriptor.
        // (Assertion - caller ensures this)
        _ = self;

        // Step 2: Assert: controller.[[byobRequest]] is null.
        // (Assertion - caller ensures this)

        // Step 3: Set pullIntoDescriptor's bytes filled to bytes filled + size.
        pull_into_descriptor.bytes_filled += size;
    }
    /// Fill pull-into descriptor from queue
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)"
    fn fillPullIntoDescriptorFromQueue(
        self: *ReadableByteStreamController,
        pull_into_descriptor: *PullIntoDescriptor,
    ) bool {
        // Step 1: Let maxBytesToCopy be min(controller.[[queueTotalSize]],
        //         pullIntoDescriptor's byte length − pullIntoDescriptor's bytes filled).
        const remaining_space = pull_into_descriptor.byte_length - pull_into_descriptor.bytes_filled;
        const max_bytes_to_copy = @min(
            @as(u64, @intFromFloat(self.queue_total_size)),
            remaining_space,
        );

        // Step 2: Let maxBytesFilled be pullIntoDescriptor's bytes filled + maxBytesToCopy.
        const max_bytes_filled = pull_into_descriptor.bytes_filled + max_bytes_to_copy;

        // Step 3: Let totalBytesToCopyRemaining be maxBytesToCopy.
        var total_bytes_to_copy_remaining = max_bytes_to_copy;

        // Step 4: Let ready be false.
        var ready = false;

        // Step 5: Assert: ! IsDetachedBuffer(pullIntoDescriptor's buffer) is false.
        // (Assertion - caller ensures this)

        // Step 6: Assert: pullIntoDescriptor's bytes filled < pullIntoDescriptor's minimum fill.
        // (Assertion - caller ensures this)

        // Step 7: Let remainderBytes be the remainder after dividing maxBytesFilled
        //         by pullIntoDescriptor's element size.
        const remainder_bytes = max_bytes_filled % pull_into_descriptor.element_size;

        // Step 8: Let maxAlignedBytes be maxBytesFilled − remainderBytes.
        const max_aligned_bytes = max_bytes_filled - remainder_bytes;

        // Step 9: If maxAlignedBytes ≥ pullIntoDescriptor's minimum fill,
        if (max_aligned_bytes >= pull_into_descriptor.minimum_fill) {
            // Step 9.1: Set totalBytesToCopyRemaining to maxAlignedBytes − pullIntoDescriptor's bytes filled.
            total_bytes_to_copy_remaining = max_aligned_bytes - pull_into_descriptor.bytes_filled;

            // Step 9.2: Set ready to true.
            ready = true;
        }

        // Step 10: Let queue be controller.[[queue]].
        // (Using self.queue directly)

        // Step 11: While totalBytesToCopyRemaining > 0,
        while (total_bytes_to_copy_remaining > 0) {
            // Step 11.1: Let headOfQueue be queue[0].
            var head_of_queue = &self.queue.items[0];

            // Step 11.2: Let bytesToCopy be min(totalBytesToCopyRemaining, headOfQueue's byte length).
            const bytes_to_copy = @min(total_bytes_to_copy_remaining, head_of_queue.byte_length);

            // Step 11.3: Let destStart be pullIntoDescriptor's byte offset + pullIntoDescriptor's bytes filled.
            const dest_start = pull_into_descriptor.byte_offset + pull_into_descriptor.bytes_filled;

            // Step 11.4: Let descriptorBuffer be pullIntoDescriptor's buffer.
            const descriptor_buffer = pull_into_descriptor.buffer;

            // Step 11.5: Let queueBuffer be headOfQueue's buffer.
            const queue_buffer = head_of_queue.buffer;

            // Step 11.6: Let queueByteOffset be headOfQueue's byte offset.
            const queue_byte_offset = head_of_queue.byte_offset;

            // Step 11.7: Assert: ! CanCopyDataBlockBytes(...) is true.
            // Step 11.8: Perform ! CopyDataBlockBytes(...).
            // Copy bytes from queue buffer to descriptor buffer
            const src_slice = queue_buffer.data[queue_byte_offset..][0..bytes_to_copy];
            const dst_slice = descriptor_buffer.data[dest_start..][0..bytes_to_copy];
            @memcpy(dst_slice, src_slice);

            // Step 11.9: If headOfQueue's byte length is bytesToCopy,
            if (head_of_queue.byte_length == bytes_to_copy) {
                // Step 11.9.1: Remove queue[0].
                _ = self.queue.orderedRemove(0);
            } else {
                // Step 11.10: Otherwise,
                // Step 11.10.1: Set headOfQueue's byte offset to headOfQueue's byte offset + bytesToCopy.
                head_of_queue.byte_offset += bytes_to_copy;

                // Step 11.10.2: Set headOfQueue's byte length to headOfQueue's byte length − bytesToCopy.
                head_of_queue.byte_length -= bytes_to_copy;
            }

            // Step 11.11: Set controller.[[queueTotalSize]] to controller.[[queueTotalSize]] − bytesToCopy.
            self.queue_total_size -= @as(f64, @floatFromInt(bytes_to_copy));

            // Step 11.12: Perform ! ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesToCopy, pullIntoDescriptor).
            self.fillHeadPullIntoDescriptor(bytes_to_copy, pull_into_descriptor);

            // Step 11.13: Set totalBytesToCopyRemaining to totalBytesToCopyRemaining − bytesToCopy.
            total_bytes_to_copy_remaining -= bytes_to_copy;
        }

        // Step 12: If ready is false,
        if (!ready) {
            // Step 12.1: Assert: controller.[[queueTotalSize]] is 0.
            // Step 12.2: Assert: pullIntoDescriptor's bytes filled > 0.
            // Step 12.3: Assert: pullIntoDescriptor's bytes filled < pullIntoDescriptor's minimum fill.
            // (Assertions - validated by algorithm logic)
        }

        // Step 13: Return ready.
        return ready;
    }
    /// Shift (remove) the first pending pull-into descriptor
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerShiftPendingPullInto(controller)"
    fn shiftPendingPullInto(self: *ReadableByteStreamController) *PullIntoDescriptor {
        // Step 1: Assert: controller.[[byobRequest]] is null.
        // (Assertion - caller ensures this)

        // Step 2: Return ! controller.[[pendingPullIntos]].shift().
        return self.pending_pull_intos.orderedRemove(0);
    }
    /// Convert pull-into descriptor to typed array view
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor)"
    fn convertPullIntoDescriptor(
        self: *ReadableByteStreamController,
        pull_into_descriptor: *PullIntoDescriptor,
    ) !webidl.ArrayBufferView {
        // Step 1: Let bytesFilled be pullIntoDescriptor's bytes filled.
        const bytes_filled = pull_into_descriptor.bytes_filled;

        // Step 2: Let elementSize be pullIntoDescriptor's element size.
        const element_size = pull_into_descriptor.element_size;

        // Step 3: Assert: bytesFilled ≤ pullIntoDescriptor's byte length.
        // (Assertion - enforced by fill algorithms)

        // Step 4: Assert: the remainder after dividing bytesFilled by elementSize is 0.
        // (Assertion - enforced by fill algorithms)

        // Step 5: Let buffer be ! TransferArrayBuffer(pullIntoDescriptor's buffer).
        const transferred_buffer = try pull_into_descriptor.buffer.transfer();

        // We need to allocate the transferred buffer on heap for view construction
        const buffer_ptr = try self.allocator.create(ArrayBuffer);
        buffer_ptr.* = transferred_buffer;

        // Step 6: Return ! Construct(pullIntoDescriptor's view constructor,
        //         « buffer, pullIntoDescriptor's byte offset, bytesFilled ÷ elementSize »).
        const length = bytes_filled / element_size;

        return try view_construction.constructView(
            pull_into_descriptor.view_constructor,
            buffer_ptr,
            pull_into_descriptor.byte_offset,
            length,
        );
    }
    /// Process pull-into descriptors using queue
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller)"
    fn processPullIntoDescriptorsUsingQueue(
        self: *ReadableByteStreamController,
    ) !std.ArrayList(*PullIntoDescriptor) {
        // Step 1: Assert: controller.[[closeRequested]] is false.
        // (Assertion - caller ensures this)

        // Step 2: Let filledPullIntos be a new empty list.
        var filled_pull_intos: std.ArrayList(*PullIntoDescriptor) = .{};
        errdefer filled_pull_intos.deinit(self.allocator);

        // Step 3: While controller.[[pendingPullIntos]] is not empty,
        while (self.pending_pull_intos.items.len > 0) {
            // Step 3.1: If controller.[[queueTotalSize]] is 0, then break.
            if (self.queue_total_size == 0) {
                break;
            }

            // Step 3.2: Let pullIntoDescriptor be controller.[[pendingPullIntos]][0].
            const pull_into_descriptor = self.pending_pull_intos.items[0];

            // Step 3.3: If ! ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor) is true,
            if (self.fillPullIntoDescriptorFromQueue(pull_into_descriptor)) {
                // Step 3.3.1: Perform ! ReadableByteStreamControllerShiftPendingPullInto(controller).
                const shifted = self.shiftPendingPullInto();

                // Step 3.3.2: Append pullIntoDescriptor to filledPullIntos.
                try filled_pull_intos.append(self.allocator, shifted);
            }
        }

        // Step 4: Return filledPullIntos.
        return filled_pull_intos;
    }
    /// Handle queue drain (empty queue with close requested)
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerHandleQueueDrain(controller)"
    fn handleQueueDrain(self: *ReadableByteStreamController) void {
        // Step 1: Assert: controller.[[stream]].[[state]] is "readable".
        // (Assertion - caller ensures this)

        // Step 2: If controller.[[queueTotalSize]] is 0 and controller.[[closeRequested]] is true,
        if (self.queue_total_size == 0.0 and self.close_requested) {
            // Step 2.1: Perform ! ReadableByteStreamControllerClearAlgorithms(controller).
            self.clearAlgorithms();

            // Step 2.2: Perform ! ReadableStreamClose(controller.[[stream]]).
            if (self.stream) |stream| {
                stream.closeInternal();
            }
        } else {
            // Step 3: Otherwise, perform ! ReadableByteStreamControllerCallPullIfNeeded(controller).
            self.callPullIfNeeded();
        }
    }
    /// Check if pull should be called
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerShouldCallPull(controller)"
    fn shouldCallPull(self: *const ReadableByteStreamController) bool {
        // Step 1: Let stream be controller.[[stream]].
        const stream = self.stream orelse return false;

        // Step 2: If stream.[[state]] is not "readable", return false.
        if (stream.state != .readable) {
            return false;
        }

        // Step 3: If controller.[[closeRequested]] is true, return false.
        if (self.close_requested) {
            return false;
        }

        // Step 4: If controller.[[started]] is false, return false.
        if (!self.started) {
            return false;
        }

        // Step 5: If ! ReadableStreamHasDefaultReader(stream) is true and
        //         ! ReadableStreamGetNumReadRequests(stream) > 0, return true.
        if (stream.hasDefaultReader() and stream.getNumReadRequests() > 0) {
            return true;
        }

        // Step 6: If ! ReadableStreamHasBYOBReader(stream) is true and
        //         ! ReadableStreamGetNumReadIntoRequests(stream) > 0, return true.
        if (stream.hasBYOBReader() and stream.getNumReadIntoRequests() > 0) {
            return true;
        }

        // Step 7: Let desiredSize be ! ReadableByteStreamControllerGetDesiredSize(controller).
        const desired_size = self.calculateDesiredSize();

        // Step 8: Assert: desiredSize is not null.
        // (Should always have a value in current state)

        // Step 9: If desiredSize > 0, return true.
        if (desired_size) |size| {
            if (size > 0) {
                return true;
            }
        }

        // Step 10: Return false.
        return false;
    }
    /// Call pull if needed
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerCallPullIfNeeded(controller)"
    fn callPullIfNeeded(self: *ReadableByteStreamController) void {
        // Step 1: Let shouldPull be ! ReadableByteStreamControllerShouldCallPull(controller).
        const should_pull = self.shouldCallPull();

        // Step 2: If shouldPull is false, return.
        if (!should_pull) {
            return;
        }

        // Step 3: If controller.[[pulling]] is true,
        if (self.pulling) {
            // Step 3.1: Set controller.[[pullAgain]] to true.
            self.pull_again = true;

            // Step 3.2: Return.
            return;
        }

        // Step 4: Assert: controller.[[pullAgain]] is false.
        // (Ensured by logic above)

        // Step 5: Set controller.[[pulling]] to true.
        self.pulling = true;

        // Step 6: Let pullPromise be the result of performing controller.[[pullAlgorithm]].
        const pull_result = self.pull_algorithm.call();

        // Step 7: Upon fulfillment of pullPromise,
        if (pull_result.isFulfilled()) {
            // Step 7.1: Set controller.[[pulling]] to false.
            self.pulling = false;

            // Step 7.2: If controller.[[pullAgain]] is true,
            if (self.pull_again) {
                // Step 7.2.1: Set controller.[[pullAgain]] to false.
                self.pull_again = false;

                // Step 7.2.2: Perform ! ReadableByteStreamControllerCallPullIfNeeded(controller).
                self.callPullIfNeeded();
            }
        }

        // Step 8: Upon rejection of pullPromise with reason e,
        if (pull_result.isRejected()) {
            // Step 8.1: Perform ! ReadableByteStreamControllerError(controller, e).
            const error_value = pull_result.error_value orelse common.JSValue{ .string = "Pull failed" };
            self.errorInternal(error_value);
        }
    }
    /// Process all pending read requests using queue
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerProcessReadRequestsUsingQueue(controller)"
    fn processReadRequestsUsingQueue(self: *ReadableByteStreamController) !void {
        // Step 1: Let reader be controller.[[stream]].[[reader]].
        const stream = self.stream orelse return;

        // Step 2: Assert: reader implements ReadableStreamDefaultReader.
        // (Validated by checking reader type)

        // Step 3: While reader.[[readRequests]] is not empty,
        while (stream.getNumReadRequests() > 0) {
            // Step 3.1: If controller.[[queueTotalSize]] is 0, return.
            if (self.queue_total_size == 0) {
                return;
            }

            // Step 3.2-3.3: Let readRequest be reader.[[readRequests]][0], remove it
            // Step 3.4: Perform ! ReadableByteStreamControllerFillReadRequestFromQueue(controller, readRequest).
            try self.fillReadRequestFromQueue();
        }
    }
    /// Fill a read request from the queue (for default readers)
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerFillReadRequestFromQueue(controller, readRequest)"
    fn fillReadRequestFromQueue(self: *ReadableByteStreamController) !void {
        // Step 1: Assert: controller.[[queueTotalSize]] > 0.
        // (Assertion - caller ensures this)

        // Step 2: Let entry be controller.[[queue]][0].
        const entry = self.queue.items[0];

        // Step 3: Remove entry from controller.[[queue]].
        _ = self.queue.orderedRemove(0);

        // Step 4: Set controller.[[queueTotalSize]] to controller.[[queueTotalSize]] − entry's byte length.
        self.queue_total_size -= @as(f64, @floatFromInt(entry.byte_length));

        // Step 5: Perform ! ReadableByteStreamControllerHandleQueueDrain(controller).
        self.handleQueueDrain();

        // Step 6: Let view be ! Construct(%Uint8Array%, « entry's buffer, entry's byte offset, entry's byte length »).
        const view = try view_construction.constructView(
            ViewConstructor.uint8_array,
            entry.buffer,
            entry.byte_offset,
            entry.byte_length,
        );

        // Step 7: Perform readRequest's chunk steps, given view.
        // In our implementation, we fulfill the stream's pending read request
        if (self.stream) |stream| {
            // Convert view to JSValue for fulfillment
            // TODO: Properly convert ArrayBufferView to JSValue
            _ = view; // View construction for type validation
            const chunk_value = common.JSValue{ .object = {} };
            stream.fulfillReadRequest(chunk_value, false);
        }
    }
    /// Initiate a BYOB read operation
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerPullInto(controller, view, min, readIntoRequest)"
    pub fn pullInto(
        self: *ReadableByteStreamController,
        view: webidl.ArrayBufferView,
        min: u64,
        read_into_request: ReadIntoRequest,
    ) !void {
        // Step 1: Let stream be controller.[[stream]].
        const stream = self.stream orelse return error.NoStream;

        // Steps 2-4: Determine element size and constructor from view using webidl 0.7.0
        const element_size: u64 = view.getElementSize();

        // Map TypedArrayName to ViewConstructor
        const ctor = if (view.getTypedArrayName()) |name| blk: {
            break :blk switch (name) {
                .Int8Array => ViewConstructor.int8_array,
                .Uint8Array => ViewConstructor.uint8_array,
                .Uint8ClampedArray => ViewConstructor.uint8_clamped_array,
                .Int16Array => ViewConstructor.int16_array,
                .Uint16Array => ViewConstructor.uint16_array,
                .Int32Array => ViewConstructor.int32_array,
                .Uint32Array => ViewConstructor.uint32_array,
                .BigInt64Array => ViewConstructor.bigint64_array,
                .BigUint64Array => ViewConstructor.biguint64_array,
                .Float32Array => ViewConstructor.float32_array,
                .Float64Array => ViewConstructor.float64_array,
            };
        } else ViewConstructor.data_view;

        // Step 5: Let minimumFill be min × elementSize.
        const minimum_fill = min * element_size;

        // Step 6: Assert: minimumFill ≥ 0 and minimumFill ≤ view.[[ByteLength]].
        // Step 7: Assert: the remainder after dividing minimumFill by elementSize is 0.
        // (Assertions - caller ensures these)

        // Step 8-9: Extract byteOffset and byteLength from view using webidl 0.7.0
        const byte_offset: u64 = @intCast(view.getByteOffset());
        const byte_length: u64 = @intCast(view.getByteLength());

        // Step 10: Let bufferResult be TransferArrayBuffer(view.[[ViewedArrayBuffer]]).
        const view_buffer = view.getViewedArrayBuffer();
        // Convert webidl.ArrayBuffer to internal ArrayBuffer
        const internal_view_buffer = try convertWebIDLArrayBuffer(self.allocator, view_buffer.*);

        // Step 11-12: Handle transfer errors
        const transferred_buffer = try internal_view_buffer.transfer();
        const buffer_ptr = try self.allocator.create(ArrayBuffer);
        buffer_ptr.* = transferred_buffer;
        // Clean up temporary buffer
        self.allocator.destroy(internal_view_buffer);

        // Step 13: Create pull-into descriptor
        const pull_into_descriptor = try self.allocator.create(PullIntoDescriptor);
        pull_into_descriptor.* = .{
            .buffer = buffer_ptr,
            .buffer_byte_length = buffer_ptr.data.len,
            .byte_offset = byte_offset,
            .byte_length = byte_length,
            .bytes_filled = 0,
            .minimum_fill = minimum_fill,
            .element_size = element_size,
            .view_constructor = ctor,
            .reader_type = .byob,
        };

        // Step 14: If controller.[[pendingPullIntos]] is not empty,
        if (self.pending_pull_intos.items.len > 0) {
            // Step 14.1-14.3: Append descriptor and add read-into request
            try self.pending_pull_intos.append(self.allocator, pull_into_descriptor);
            // TODO: Add readIntoRequest to stream.[[reader]].[[readIntoRequests]]
            _ = read_into_request;
            return;
        }

        // Step 15: If stream.[[state]] is "closed",
        if (stream.state == .closed) {
            // Step 15.1: Let emptyView be ! Construct(ctor, « pullIntoDescriptor's buffer, pullIntoDescriptor's byte offset, 0 »).
            const empty_view = try view_construction.constructView(ctor, buffer_ptr, byte_offset, 0);

            // Step 15.2: Perform readIntoRequest's close steps, given emptyView.
            // TODO: Call readIntoRequest.close_steps(empty_view)
            _ = empty_view;
            _ = read_into_request;
            return;
        }

        // Step 16: If controller.[[queueTotalSize]] > 0,
        if (self.queue_total_size > 0) {
            // Step 16.1: If ! ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor) is true,
            if (self.fillPullIntoDescriptorFromQueue(pull_into_descriptor)) {
                // Step 16.1.1: Let filledView be ! ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor).
                const filled_view = try self.convertPullIntoDescriptor(pull_into_descriptor);

                // Step 16.1.2: Perform ! ReadableByteStreamControllerHandleQueueDrain(controller).
                self.handleQueueDrain();

                // Step 16.1.3: Perform readIntoRequest's chunk steps, given filledView.
                // TODO: Call readIntoRequest.chunk_steps(filled_view)
                _ = filled_view;
                _ = read_into_request;
                return;
            }

            // Step 16.2: If controller.[[closeRequested]] is true,
            if (self.close_requested) {
                // Step 16.2.1: Let e be a TypeError exception.
                // Step 16.2.2: Perform ! ReadableByteStreamControllerError(controller, e).
                const error_value = common.JSValue{ .string = "Stream closed before filling BYOB request" };
                self.errorInternal(error_value);

                // Step 16.2.3: Perform readIntoRequest's error steps, given e.
                // TODO: Call readIntoRequest.error_steps(e)
                _ = read_into_request;
                return;
            }
        }

        // Step 17: Append pullIntoDescriptor to controller.[[pendingPullIntos]].
        try self.pending_pull_intos.append(self.allocator, pull_into_descriptor);

        // Step 18: Perform ! ReadableStreamAddReadIntoRequest(stream, readIntoRequest).
        // TODO: Add readIntoRequest to stream.[[reader]].[[readIntoRequests]]
        _ = read_into_request;

        // Step 19: Perform ! ReadableByteStreamControllerCallPullIfNeeded(controller).
        self.callPullIfNeeded();
    }
    /// Respond with a new view (replacement buffer)
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerRespondWithNewView(controller, view)"
    fn respondWithNewView(self: *ReadableByteStreamController, view: webidl.ArrayBufferView) !void {
        // Step 1: Assert: controller.[[pendingPullIntos]] is not empty.
        if (self.pending_pull_intos.items.len == 0) {
            return error.InvalidState;
        }

        // Step 2: Assert: ! IsDetachedBuffer(view.[[ViewedArrayBuffer]]) is false.
        if (view.isDetached()) {
            return error.DetachedBuffer;
        }

        // Step 3: Let firstDescriptor be controller.[[pendingPullIntos]][0].
        const first_descriptor = self.pending_pull_intos.items[0];

        // Step 4: Let state be controller.[[stream]].[[state]].
        const stream = self.stream orelse return error.NoStream;
        const state = stream.state;

        // Steps 5-6: Extract ByteLength from view using webidl 0.7.0
        const view_byte_offset: u64 = @intCast(view.getByteOffset());
        const view_byte_length: u64 = @intCast(view.getByteLength());
        const view_buffer = view.getViewedArrayBuffer();

        // Step 5: If state is "closed",
        if (state == .closed) {
            // Step 5.1: If view.[[ByteLength]] is not 0, throw a TypeError exception.
            if (view_byte_length != 0) {
                return error.TypeError;
            }
        } else {
            // Step 6: Otherwise,
            // Step 6.1: Assert: state is "readable".
            // Step 6.2: If view.[[ByteLength]] is 0, throw a TypeError exception.
            if (view_byte_length == 0) {
                return error.TypeError;
            }
        }

        // Step 7: If firstDescriptor's byte offset + firstDescriptor's bytes filled is not view.[[ByteOffset]], throw a RangeError exception.
        if (first_descriptor.byte_offset + first_descriptor.bytes_filled != view_byte_offset) {
            return error.RangeError;
        }

        // Step 8: If firstDescriptor's buffer byte length is not view.[[ViewedArrayBuffer]].[[ByteLength]], throw a RangeError exception.
        if (first_descriptor.buffer_byte_length != view_buffer.data.len) {
            return error.RangeError;
        }

        // Step 9: If firstDescriptor's bytes filled + view.[[ByteLength]] > firstDescriptor's byte length, throw a RangeError exception.
        if (first_descriptor.bytes_filled + view_byte_length > first_descriptor.byte_length) {
            return error.RangeError;
        }

        // Step 10: Let viewByteLength be view.[[ByteLength]].
        // (Already extracted above)

        // Step 11: Set firstDescriptor's buffer to ? TransferArrayBuffer(view.[[ViewedArrayBuffer]]).
        // Convert webidl.ArrayBuffer to internal ArrayBuffer
        const internal_view_buffer2 = try convertWebIDLArrayBuffer(self.allocator, view_buffer);
        const transferred_buffer = try internal_view_buffer2.transfer();
        first_descriptor.buffer.* = transferred_buffer;
        // Clean up temporary buffer
        self.allocator.destroy(internal_view_buffer2);

        // Step 12: Perform ? ReadableByteStreamControllerRespondInternal(controller, viewByteLength).
        try self.respondInternal(view_byte_length);
    }
    /// Public respond API for BYOB reads
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerRespond(controller, bytesWritten)"
    fn respond(self: *ReadableByteStreamController, bytes_written: u64) !void {
        // Step 1: Assert: controller.[[pendingPullIntos]] is not empty.
        if (self.pending_pull_intos.items.len == 0) {
            return error.InvalidState;
        }

        // Step 2: Let firstDescriptor be controller.[[pendingPullIntos]][0].
        const first_descriptor = self.pending_pull_intos.items[0];

        // Step 3: Let state be controller.[[stream]].[[state]].
        const stream = self.stream orelse return error.NoStream;
        const state = stream.state;

        // Step 4: If state is "closed",
        if (state == .closed) {
            // Step 4.1: If bytesWritten is not 0, throw a TypeError exception.
            if (bytes_written != 0) {
                return error.TypeError;
            }
        } else {
            // Step 5: Otherwise,
            // Step 5.1: Assert: state is "readable".
            // Step 5.2: If bytesWritten is 0, throw a TypeError exception.
            if (bytes_written == 0) {
                return error.TypeError;
            }

            // Step 5.3: If firstDescriptor's bytes filled + bytesWritten > firstDescriptor's byte length, throw a RangeError exception.
            if (first_descriptor.bytes_filled + bytes_written > first_descriptor.byte_length) {
                return error.RangeError;
            }
        }

        // Step 6: Set firstDescriptor's buffer to ! TransferArrayBuffer(firstDescriptor's buffer).
        const old_descriptor_buffer = first_descriptor.buffer;
        const transferred_desc = try old_descriptor_buffer.transfer();
        const transferred_desc_ptr = try self.allocator.create(ArrayBuffer);
        transferred_desc_ptr.* = transferred_desc;
        first_descriptor.buffer = transferred_desc_ptr;
        self.allocator.destroy(old_descriptor_buffer);

        // Step 7: Perform ? ReadableByteStreamControllerRespondInternal(controller, bytesWritten).
        try self.respondInternal(bytes_written);
    }
    /// Internal respond implementation
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerRespondInternal(controller, bytesWritten)"
    fn respondInternal(self: *ReadableByteStreamController, bytes_written: u64) !void {
        // Step 1: Let firstDescriptor be controller.[[pendingPullIntos]][0].
        const first_descriptor = self.pending_pull_intos.items[0];

        // Step 2: Assert: ! CanTransferArrayBuffer(firstDescriptor's buffer) is true.
        // (Assertion)

        // Step 3: Perform ! ReadableByteStreamControllerInvalidateBYOBRequest(controller).
        self.invalidateBYOBRequest();

        // Step 4: Let state be controller.[[stream]].[[state]].
        const stream = self.stream orelse return error.NoStream;
        const state = stream.state;

        // Step 5: If state is "closed",
        if (state == .closed) {
            // Step 5.1: Assert: bytesWritten is 0.
            // Step 5.2: Perform ! ReadableByteStreamControllerRespondInClosedState(controller, firstDescriptor).
            try self.respondInClosedState(first_descriptor);
        } else {
            // Step 6: Otherwise,
            // Step 6.1: Assert: state is "readable".
            // Step 6.2: Assert: bytesWritten > 0.
            // Step 6.3: Perform ? ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, firstDescriptor).
            try self.respondInReadableState(bytes_written, first_descriptor);
        }

        // Step 7: Perform ! ReadableByteStreamControllerCallPullIfNeeded(controller).
        self.callPullIfNeeded();
    }
    /// Respond when stream is in closed state
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerRespondInClosedState(controller, firstDescriptor)"
    fn respondInClosedState(
        self: *ReadableByteStreamController,
        first_descriptor: *PullIntoDescriptor,
    ) !void {
        // Step 1: Assert: the remainder after dividing firstDescriptor's bytes filled by firstDescriptor's element size is 0.
        // (Assertion)

        // Step 2: If firstDescriptor's reader type is "none", perform ! ReadableByteStreamControllerShiftPendingPullInto(controller).
        if (first_descriptor.reader_type == .none) {
            _ = self.shiftPendingPullInto();
        }

        // Step 3: Let stream be controller.[[stream]].
        const stream = self.stream orelse return error.NoStream;

        // Step 4: If ! ReadableStreamHasBYOBReader(stream) is true,
        if (stream.hasBYOBReader()) {
            // Step 4.1: Let filledPullIntos be a new empty list.
            var filled_pull_intos: std.ArrayList(*PullIntoDescriptor) = .{};
            defer filled_pull_intos.deinit(self.allocator);

            // Step 4.2: While filledPullIntos's size < ! ReadableStreamGetNumReadIntoRequests(stream),
            while (filled_pull_intos.items.len < stream.getNumReadIntoRequests()) {
                // Step 4.2.1: Let pullIntoDescriptor be ! ReadableByteStreamControllerShiftPendingPullInto(controller).
                const pull_into_descriptor = self.shiftPendingPullInto();

                // Step 4.2.2: Append pullIntoDescriptor to filledPullIntos.
                try filled_pull_intos.append(pull_into_descriptor);
            }

            // Step 4.3: For each filledPullInto of filledPullIntos,
            for (filled_pull_intos.items) |filled_pull_into| {
                // Step 4.3.1: Perform ! ReadableByteStreamControllerCommitPullIntoDescriptor(stream, filledPullInto).
                try self.commitPullIntoDescriptor(filled_pull_into);
            }
        }
    }
    /// Respond to BYOB read when stream is in readable state
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, pullIntoDescriptor)"
    fn respondInReadableState(
        self: *ReadableByteStreamController,
        bytes_written: u64,
        pull_into_descriptor: *PullIntoDescriptor,
    ) !void {
        // Step 1: Assert: pullIntoDescriptor's bytes filled + bytesWritten ≤ pullIntoDescriptor's byte length.
        // (Assertion - caller ensures this)

        // Step 2: Perform ! ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesWritten, pullIntoDescriptor).
        self.fillHeadPullIntoDescriptor(bytes_written, pull_into_descriptor);

        // Step 3: If pullIntoDescriptor's reader type is "none",
        if (pull_into_descriptor.reader_type == .none) {
            // Step 3.1: Perform ? ReadableByteStreamControllerEnqueueDetachedPullIntoToQueue(controller, pullIntoDescriptor).
            try self.enqueueDetachedPullIntoToQueue(pull_into_descriptor);

            // Step 3.2: Let filledPullIntos be the result of performing ! ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller).
            var filled_pull_intos = try self.processPullIntoDescriptorsUsingQueue();
            defer filled_pull_intos.deinit(self.allocator);

            // Step 3.3: For each filledPullInto of filledPullIntos,
            for (filled_pull_intos.items) |filled_pull_into| {
                // Step 3.3.1: Perform ! ReadableByteStreamControllerCommitPullIntoDescriptor(controller.[[stream]], filledPullInto).
                try self.commitPullIntoDescriptor(filled_pull_into);
            }

            // Step 3.4: Return.
            return;
        }

        // Step 4: If pullIntoDescriptor's bytes filled < pullIntoDescriptor's minimum fill, return.
        if (pull_into_descriptor.bytes_filled < pull_into_descriptor.minimum_fill) {
            return;
        }

        // Step 5: Perform ! ReadableByteStreamControllerShiftPendingPullInto(controller).
        _ = self.shiftPendingPullInto();

        // Step 6: Let remainderSize be the remainder after dividing pullIntoDescriptor's bytes filled by pullIntoDescriptor's element size.
        const remainder_size = pull_into_descriptor.bytes_filled % pull_into_descriptor.element_size;

        // Step 7: If remainderSize > 0,
        if (remainder_size > 0) {
            // Step 7.1: Let end be pullIntoDescriptor's byte offset + pullIntoDescriptor's bytes filled.
            const end = pull_into_descriptor.byte_offset + pull_into_descriptor.bytes_filled;

            // Step 7.2: Perform ? ReadableByteStreamControllerEnqueueClonedChunkToQueue(controller, pullIntoDescriptor's buffer, end − remainderSize, remainderSize).
            try self.enqueueClonedChunkToQueue(
                pull_into_descriptor.buffer,
                end - remainder_size,
                remainder_size,
            );
        }

        // Step 8: Set pullIntoDescriptor's bytes filled to pullIntoDescriptor's bytes filled − remainderSize.
        pull_into_descriptor.bytes_filled -= remainder_size;

        // Step 9: Let filledPullIntos be the result of performing ! ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller).
        const filled_pull_intos = try self.processPullIntoDescriptorsUsingQueue();
        defer filled_pull_intos.deinit();

        // Step 10: Perform ! ReadableByteStreamControllerCommitPullIntoDescriptor(controller.[[stream]], pullIntoDescriptor).
        try self.commitPullIntoDescriptor(pull_into_descriptor);

        // Step 11: For each filledPullInto of filledPullIntos,
        for (filled_pull_intos.items) |filled_pull_into| {
            // Step 11.1: Perform ! ReadableByteStreamControllerCommitPullIntoDescriptor(controller.[[stream]], filledPullInto).
            try self.commitPullIntoDescriptor(filled_pull_into);
        }
    }
    /// Commit a pull-into descriptor by converting and fulfilling
    /// 
    /// Spec: § 4.10.11 "ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor)"
    fn commitPullIntoDescriptor(
        self: *ReadableByteStreamController,
        pull_into_descriptor: *PullIntoDescriptor,
    ) !void {
        // Step 1: Assert: stream.[[state]] is not "errored".
        const stream = self.stream orelse return error.NoStream;
        // (Assertion - caller ensures this)

        // Step 2: Assert: pullIntoDescriptor's reader type is not "none".
        // (Assertion - enforced by type system)

        // Step 3: Let done be false.
        var done = false;

        // Step 4: If stream.[[state]] is "closed",
        if (stream.state == .closed) {
            // Step 4.1: Assert: the remainder after dividing pullIntoDescriptor's bytes filled
            //           by pullIntoDescriptor's element size is 0.
            // (Assertion - enforced by fill algorithms)

            // Step 4.2: Set done to true.
            done = true;
        }

        // Step 5: Let filledView be ! ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor).
        const filled_view = try self.convertPullIntoDescriptor(pull_into_descriptor);

        // Step 6: If pullIntoDescriptor's reader type is "default",
        if (pull_into_descriptor.reader_type == .default) {
            // Step 6.1: Perform ! ReadableStreamFulfillReadRequest(stream, filledView, done).
            stream.fulfillReadRequest(common.JSValue{ .object = {} }, done); // TODO: Convert filled_view to JSValue
        } else {
            // Step 7: Otherwise,
            // Step 7.1: Assert: pullIntoDescriptor's reader type is "byob".
            // Step 7.2: Perform ! ReadableStreamFulfillReadIntoRequest(stream, filledView, done).
            stream.fulfillReadIntoRequest(filled_view, done);
        }
    }
    /// [[CancelSteps]](reason) - Called when stream is canceled
    /// 
    /// Spec: § 4.10.12 "[[CancelSteps]](reason)"
    pub fn cancelSteps(self: *ReadableByteStreamController, reason: ?common.JSValue) !*AsyncPromise(void) {
        // Step 1: Perform ! ReadableByteStreamControllerClearPendingPullIntos(controller).
        self.clearPendingPullIntos();

        // Step 2: Perform ! ResetQueue(this).
        self.queue.clearRetainingCapacity();
        self.queue_total_size = 0.0;

        // Step 3: Let result be the result of performing this.[[cancelAlgorithm]], passing in reason.
        const result = self.cancel_algorithm.call(reason);

        // Step 4: Perform ! ReadableByteStreamControllerClearAlgorithms(this).
        self.clearAlgorithms();

        // Step 5: Return result (convert synchronous promise to async).
        const promise = try AsyncPromise(void).init(self.allocator, self.event_loop);
        if (result.isFulfilled()) {
            promise.fulfill({});
        } else if (result.isRejected()) {
            promise.reject(result.error_value orelse common.JSValue{ .string = "Cancel failed" });
        }
        return promise;
    }
};

